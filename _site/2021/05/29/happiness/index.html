<!DOCTYPE html>
<html lang="en-us">

  <head>
  <link href="http://gmpg.org/xfn/11" rel="profile">
  <meta http-equiv="content-type" content="text/html; charset=utf-8">

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">

  <title>
    
      Are you happy? An analysis of the World Happiness Report and Suicide Rates Overview data &middot; Przemek Zientala
    
  </title>

  
  <link rel="canonical" href="http://localhost:4000/2021/05/29/happiness/">
  

  <link rel="stylesheet" href="http://localhost:4000/public/css/poole.css">
  <link rel="stylesheet" href="http://localhost:4000/public/css/syntax.css">
  <link rel="stylesheet" href="http://localhost:4000/public/css/lanyon.css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=PT+Serif:400,400italic,700%7CPT+Sans:400">

  <link rel="apple-touch-icon-precomposed" sizes="144x144" href="http://localhost:4000/public/apple-touch-icon-precomposed.png">
  <link rel="shortcut icon" href="http://localhost:4000/public/favicon.ico">

  <link rel="alternate" type="application/rss+xml" title="RSS" href="http://localhost:4000/atom.xml">

  
</head>


  <body class="theme-base-08">

    <!-- Target for toggling the sidebar `.sidebar-checkbox` is for regular
     styles, `#sidebar-checkbox` for behavior. -->
<input type="checkbox" class="sidebar-checkbox" id="sidebar-checkbox">

<!-- Toggleable sidebar -->
<div class="sidebar" id="sidebar">
  <div class="sidebar-item">
    <p>This is my little, personal space on the vast internet; welcome! I hope you will enjoy your stay and learn a thing or two.</p>
  </div>

  <nav class="sidebar-nav">
    <a class="sidebar-nav-item" href="http://localhost:4000/">Home</a>

    

    
    
      
        
      
    
      
        
      
    
      
        
          <a class="sidebar-nav-item" href="http://localhost:4000/about/">About</a>
        
      
    
      
        
          <a class="sidebar-nav-item" href="http://localhost:4000/archive/">Archive</a>
        
      
    
      
    
      
    

    <a class="sidebar-nav-item" href="/assets/pdf/resume.pdf" target="_blank">Resume</a>
    <!--<a class="sidebar-nav-item" href="">GitHub project</a>-->
    <!--<span class="sidebar-nav-item">Currently v0.42.0</span>-->
  </nav>

  <div class="sidebar-item">
    <p>
      &copy; 2021. Przemyslaw Zientala. All rights reserved.
    </p>
  </div>
</div>


    <!-- Wrap is the content to shift when toggling the sidebar. We wrap the
         content to avoid any CSS collisions with our real content. -->
    <div class="wrap">
      <div class="masthead">
        <div class="container">
          <h3 class="masthead-title">
            <a href="/" title="Home">Przemek Zientala</a>
            <small>Notes on things</small>
          </h3>
        </div>
      </div>

      <div class="container content">
        <div class="post">
  <h1 class="post-title">Are you happy? An analysis of the World Happiness Report and Suicide Rates Overview data</h1>
  <span class="post-date">29 May 2021</span>
  <h2 id="introduction">Introduction</h2>

<h3 id="motivation">Motivation</h3>

<p>I recently took a <a href="https://www.coursera.org/learn/the-science-of-well-being">course about happiness</a> which made me rethink my approach to achieving happiness. The course mentioned some crucial contributing factors such as deep relationships, giving, or cherishing as things that, according to science, <em>truly</em> make us happy.</p>

<p>This made me think - how is happiness “distributed” around the world, how has it changed over time, and what can we learn about it by studying data showing two extremes: happiness and suicide?</p>

<h3 id="data">Data</h3>
<p>Naturally, collecting data about happiness and suicides myself would be costly and time-consuming. Therefore, I decided that the next best thing will be to find datasets on the Internet. Unsurprisingly, there are datasets covering both topics on Kaggle: the <a href="https://www.kaggle.com/mathurinache/world-happiness-report">World Happiness Report (up to 2020)</a> and <a href="https://www.kaggle.com/russellyates88/suicide-rates-overview-1985-to-2016">Suicide Rates Overview (1985 - 2016)</a>.</p>

<h3 id="approach">Approach</h3>
<p>Rather than analyzing each dataset separately, I thought it would be interesting to join them together and try to see if / what we can learn by studying happiness not only implicitly, but also by looking at suicide rates. The reason is simple - suicidal people are more likely to be unhappy on average, so we would expect to see some inverse correlations.</p>

<h1 id="data-preparation">Data preparation</h1>

<h2 id="data-cleaning">Data cleaning</h2>

<p>Let’s first have a quick look at both datasets to figure out how to merge them.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_2015</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data/world_happiness_report/2015.csv"</span><span class="p">)</span>
<span class="n">data_happiness_2016</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data/world_happiness_report/2016.csv"</span><span class="p">)</span>
<span class="n">data_happiness_2017</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data/world_happiness_report/2017.csv"</span><span class="p">)</span>
<span class="n">data_happiness_2018</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data/world_happiness_report/2018.csv"</span><span class="p">)</span>
<span class="n">data_happiness_2019</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data/world_happiness_report/2019.csv"</span><span class="p">)</span>
<span class="n">data_happiness_2020</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data/world_happiness_report/2020.csv"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_2015</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Region</th>
      <th>Happiness Rank</th>
      <th>Happiness Score</th>
      <th>Standard Error</th>
      <th>Economy (GDP per Capita)</th>
      <th>Family</th>
      <th>Health (Life Expectancy)</th>
      <th>Freedom</th>
      <th>Trust (Government Corruption)</th>
      <th>Generosity</th>
      <th>Dystopia Residual</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Switzerland</td>
      <td>Western Europe</td>
      <td>1</td>
      <td>7.587</td>
      <td>0.03411</td>
      <td>1.39651</td>
      <td>1.34951</td>
      <td>0.94143</td>
      <td>0.66557</td>
      <td>0.41978</td>
      <td>0.29678</td>
      <td>2.51738</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Iceland</td>
      <td>Western Europe</td>
      <td>2</td>
      <td>7.561</td>
      <td>0.04884</td>
      <td>1.30232</td>
      <td>1.40223</td>
      <td>0.94784</td>
      <td>0.62877</td>
      <td>0.14145</td>
      <td>0.43630</td>
      <td>2.70201</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Denmark</td>
      <td>Western Europe</td>
      <td>3</td>
      <td>7.527</td>
      <td>0.03328</td>
      <td>1.32548</td>
      <td>1.36058</td>
      <td>0.87464</td>
      <td>0.64938</td>
      <td>0.48357</td>
      <td>0.34139</td>
      <td>2.49204</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Norway</td>
      <td>Western Europe</td>
      <td>4</td>
      <td>7.522</td>
      <td>0.03880</td>
      <td>1.45900</td>
      <td>1.33095</td>
      <td>0.88521</td>
      <td>0.66973</td>
      <td>0.36503</td>
      <td>0.34699</td>
      <td>2.46531</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Canada</td>
      <td>North America</td>
      <td>5</td>
      <td>7.427</td>
      <td>0.03553</td>
      <td>1.32629</td>
      <td>1.32261</td>
      <td>0.90563</td>
      <td>0.63297</td>
      <td>0.32957</td>
      <td>0.45811</td>
      <td>2.45176</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_2020</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country name</th>
      <th>Regional indicator</th>
      <th>Ladder score</th>
      <th>Standard error of ladder score</th>
      <th>upperwhisker</th>
      <th>lowerwhisker</th>
      <th>Logged GDP per capita</th>
      <th>Social support</th>
      <th>Healthy life expectancy</th>
      <th>Freedom to make life choices</th>
      <th>Generosity</th>
      <th>Perceptions of corruption</th>
      <th>Ladder score in Dystopia</th>
      <th>Explained by: Log GDP per capita</th>
      <th>Explained by: Social support</th>
      <th>Explained by: Healthy life expectancy</th>
      <th>Explained by: Freedom to make life choices</th>
      <th>Explained by: Generosity</th>
      <th>Explained by: Perceptions of corruption</th>
      <th>Dystopia + residual</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Finland</td>
      <td>Western Europe</td>
      <td>7.8087</td>
      <td>0.031156</td>
      <td>7.869766</td>
      <td>7.747634</td>
      <td>10.639267</td>
      <td>0.954330</td>
      <td>71.900825</td>
      <td>0.949172</td>
      <td>-0.059482</td>
      <td>0.195445</td>
      <td>1.972317</td>
      <td>1.285190</td>
      <td>1.499526</td>
      <td>0.961271</td>
      <td>0.662317</td>
      <td>0.159670</td>
      <td>0.477857</td>
      <td>2.762835</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Denmark</td>
      <td>Western Europe</td>
      <td>7.6456</td>
      <td>0.033492</td>
      <td>7.711245</td>
      <td>7.579955</td>
      <td>10.774001</td>
      <td>0.955991</td>
      <td>72.402504</td>
      <td>0.951444</td>
      <td>0.066202</td>
      <td>0.168489</td>
      <td>1.972317</td>
      <td>1.326949</td>
      <td>1.503449</td>
      <td>0.979333</td>
      <td>0.665040</td>
      <td>0.242793</td>
      <td>0.495260</td>
      <td>2.432741</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Switzerland</td>
      <td>Western Europe</td>
      <td>7.5599</td>
      <td>0.035014</td>
      <td>7.628528</td>
      <td>7.491272</td>
      <td>10.979933</td>
      <td>0.942847</td>
      <td>74.102448</td>
      <td>0.921337</td>
      <td>0.105911</td>
      <td>0.303728</td>
      <td>1.972317</td>
      <td>1.390774</td>
      <td>1.472403</td>
      <td>1.040533</td>
      <td>0.628954</td>
      <td>0.269056</td>
      <td>0.407946</td>
      <td>2.350267</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Iceland</td>
      <td>Western Europe</td>
      <td>7.5045</td>
      <td>0.059616</td>
      <td>7.621347</td>
      <td>7.387653</td>
      <td>10.772559</td>
      <td>0.974670</td>
      <td>73.000000</td>
      <td>0.948892</td>
      <td>0.246944</td>
      <td>0.711710</td>
      <td>1.972317</td>
      <td>1.326502</td>
      <td>1.547567</td>
      <td>1.000843</td>
      <td>0.661981</td>
      <td>0.362330</td>
      <td>0.144541</td>
      <td>2.460688</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Norway</td>
      <td>Western Europe</td>
      <td>7.4880</td>
      <td>0.034837</td>
      <td>7.556281</td>
      <td>7.419719</td>
      <td>11.087804</td>
      <td>0.952487</td>
      <td>73.200783</td>
      <td>0.955750</td>
      <td>0.134533</td>
      <td>0.263218</td>
      <td>1.972317</td>
      <td>1.424207</td>
      <td>1.495173</td>
      <td>1.008072</td>
      <td>0.670201</td>
      <td>0.287985</td>
      <td>0.434101</td>
      <td>2.168266</td>
    </tr>
  </tbody>
</table>
</div>

<p>We can already see that not only do some column names have different names, but also we have different sets of columns depending on the year data was collected. This means we will have to:</p>

<ol>
  <li>Agree on which columns to keep</li>
  <li>Agree on common names for these columns</li>
</ol>

<h3 id="column-name-cleanup">Column name cleanup</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_2015</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['Country', 'Region', 'Happiness Rank', 'Happiness Score',
       'Standard Error', 'Economy (GDP per Capita)', 'Family',
       'Health (Life Expectancy)', 'Freedom', 'Trust (Government Corruption)',
       'Generosity', 'Dystopia Residual'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_2016</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['Country', 'Region', 'Happiness Rank', 'Happiness Score',
       'Lower Confidence Interval', 'Upper Confidence Interval',
       'Economy (GDP per Capita)', 'Family', 'Health (Life Expectancy)',
       'Freedom', 'Trust (Government Corruption)', 'Generosity',
       'Dystopia Residual'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_2017</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['Country', 'Happiness.Rank', 'Happiness.Score', 'Whisker.high',
       'Whisker.low', 'Economy..GDP.per.Capita.', 'Family',
       'Health..Life.Expectancy.', 'Freedom', 'Generosity',
       'Trust..Government.Corruption.', 'Dystopia.Residual'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_2018</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['Overall rank', 'Country or region', 'Score', 'GDP per capita',
       'Social support', 'Healthy life expectancy',
       'Freedom to make life choices', 'Generosity',
       'Perceptions of corruption'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_2019</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['Overall rank', 'Country or region', 'Score', 'GDP per capita',
       'Social support', 'Healthy life expectancy',
       'Freedom to make life choices', 'Generosity',
       'Perceptions of corruption'],
      dtype='object')
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_2020</span><span class="p">.</span><span class="n">columns</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Index(['Country name', 'Regional indicator', 'Ladder score',
       'Standard error of ladder score', 'upperwhisker', 'lowerwhisker',
       'Logged GDP per capita', 'Social support', 'Healthy life expectancy',
       'Freedom to make life choices', 'Generosity',
       'Perceptions of corruption', 'Ladder score in Dystopia',
       'Explained by: Log GDP per capita', 'Explained by: Social support',
       'Explained by: Healthy life expectancy',
       'Explained by: Freedom to make life choices',
       'Explained by: Generosity', 'Explained by: Perceptions of corruption',
       'Dystopia + residual'],
      dtype='object')
</code></pre></div></div>

<p>Below, I’ll list the concepts which columns describe for each dataset:</p>

<ol>
  <li>Country:
    <ul>
      <li>2015: Country</li>
      <li>2016: Country</li>
      <li>2017: Country</li>
      <li>2018: Country or region</li>
      <li>2019: Country or region</li>
      <li>2020: Country name</li>
    </ul>
  </li>
  <li>Happiness score:
    <ul>
      <li>2015: Happiness Score</li>
      <li>2016: Happiness Score</li>
      <li>2017: Happiness.Score</li>
      <li>2018: Score</li>
      <li>2019: Score</li>
      <li>2020: Ladder score</li>
    </ul>
  </li>
  <li>GDP per capita:
    <ul>
      <li>2015: Economy (GDP per Capita)</li>
      <li>2016: Economy (GDP per Capita)</li>
      <li>2017: Economy..GDP.per.Capita.</li>
      <li>2018: GDP per capita</li>
      <li>2019: GDP per capita</li>
      <li>2020: Logged GDP per capita</li>
    </ul>
  </li>
  <li>Family:
    <ul>
      <li>2015: Family</li>
      <li>2016: Family</li>
      <li>2017: Family</li>
      <li>2018: Social support</li>
      <li>2019: Social support</li>
      <li>2020: Social support</li>
    </ul>
  </li>
  <li>Health:
    <ul>
      <li>2015: Health (Life Expectancy)</li>
      <li>2016: Health (Life Expectancy)</li>
      <li>2017: Health..Life.Expectancy.</li>
      <li>2018: Healthy life expectancy</li>
      <li>2019: Healthy life expectancy</li>
      <li>2020: Healthy life expectancy</li>
    </ul>
  </li>
  <li>Freedom:
    <ul>
      <li>2015: Freedom</li>
      <li>2016: Freedom</li>
      <li>2017: Freedom</li>
      <li>2018: Freedom to make life choices</li>
      <li>2019: Freedom to make life choices</li>
      <li>2020: Freedom to make life choices</li>
    </ul>
  </li>
  <li>Trust:
    <ul>
      <li>2015: Trust (Government Corruption)</li>
      <li>2016: Trust (Government Corruption)</li>
      <li>2017: Trust..Government.Corruption.</li>
      <li>2018: Perceptions of corruption</li>
      <li>2019: Perceptions of corruption</li>
      <li>2020: Perceptions of corruption</li>
    </ul>
  </li>
  <li>Generosity:
    <ul>
      <li>2015: Generosity</li>
      <li>2016: Generosity</li>
      <li>2017: Generosity</li>
      <li>2018: Generosity</li>
      <li>2019: Generosity</li>
      <li>2020: Generosity</li>
    </ul>
  </li>
</ol>

<p>Additionally, we will keep a column “Region” in all datasets based on the values of that column in the most recent dataset where it was still present (2016).</p>

<p>The above list clearly illustrates why data cleaning is such a crucial and time-consuming step before any data analysis. Now that we know how to merge these datasets using column names, let’s change the column names to the common ones to facilitate further data cleaning.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Create a mapping of country name to region, will be useful for further analysis
</span><span class="n">region_mapping</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">Series</span><span class="p">(</span><span class="n">data_happiness_2016</span><span class="p">.</span><span class="n">Region</span><span class="p">.</span><span class="n">values</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="n">data_happiness_2016</span><span class="p">.</span><span class="n">Country</span><span class="p">).</span><span class="n">to_dict</span><span class="p">()</span>

<span class="k">class</span> <span class="nc">ColumnCleaner</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df_list</span><span class="p">,</span> <span class="n">region_mapping</span><span class="p">):</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">df_list</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="nb">IndexError</span><span class="p">(</span><span class="s">"Empty list was provided"</span><span class="p">)</span>
            
        <span class="bp">self</span><span class="p">.</span><span class="n">df_list</span> <span class="o">=</span> <span class="n">df_list</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">region_mapping</span> <span class="o">=</span> <span class="n">region_mapping</span>
        
        <span class="c1"># Define sets mapping to common column names
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">country_set</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Country"</span><span class="p">,</span> <span class="s">"Country or region"</span><span class="p">,</span> <span class="s">"Country name"</span><span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">happiness_set</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Happiness Score"</span><span class="p">,</span> <span class="s">"Happiness.Score"</span><span class="p">,</span> <span class="s">"Score"</span><span class="p">,</span> <span class="s">"Ladder score"</span><span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">gdp_set</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Economy (GDP per Capita)"</span><span class="p">,</span> <span class="s">"Economy..GDP.per.Capita."</span><span class="p">,</span> <span class="s">"GDP per capita"</span><span class="p">,</span> <span class="s">"Logged GDP per capita"</span><span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">family_set</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Family"</span><span class="p">,</span> <span class="s">"Social support"</span><span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">health_set</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Health (Life Expectancy)"</span><span class="p">,</span> <span class="s">"Health..Life.Expectancy."</span><span class="p">,</span> <span class="s">"Healthy life expectancy"</span><span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">freedom_set</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Freedom to make life choices"</span><span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">trust_set</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Trust (Government Corruption)"</span><span class="p">,</span> <span class="s">"Trust..Government.Corruption."</span><span class="p">,</span> <span class="s">"Perceptions of corruption"</span><span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">generosity_set</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Generosity"</span><span class="p">}</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">set_list</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="p">.</span><span class="n">country_set</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">happiness_set</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">gdp_set</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">family_set</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">health_set</span><span class="p">,</span> 
                         <span class="bp">self</span><span class="p">.</span><span class="n">freedom_set</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">trust_set</span><span class="p">,</span> <span class="bp">self</span><span class="p">.</span><span class="n">generosity_set</span><span class="p">]</span>
        
        <span class="c1"># Define common names to use for concepts
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">common_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Country"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]</span>
        
    <span class="c1"># Remap column names
</span>    <span class="k">def</span> <span class="nf">remap_column_names</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">set_list</span><span class="p">)):</span>
            <span class="n">column_name_current</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">set_list</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">intersection</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
            <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="n">column_name_current</span><span class="p">:</span> <span class="bp">self</span><span class="p">.</span><span class="n">common_names</span><span class="p">[</span><span class="n">i</span><span class="p">]})</span>
            
        <span class="k">return</span> <span class="n">df</span>

    <span class="c1"># Drop unnecessary columns in-place
</span>    <span class="k">def</span> <span class="nf">drop_columns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">[</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">.</span><span class="n">isin</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">common_names</span><span class="p">)]]</span>
    
    <span class="c1"># Add a "Region" column. Apply this function after remapping column names
</span>    <span class="k">def</span> <span class="nf">add_region_column</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">df</span><span class="p">):</span>
        <span class="n">df</span><span class="p">[</span><span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">"Country"</span><span class="p">].</span><span class="nb">map</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">region_mapping</span><span class="p">)</span>
        
        <span class="k">return</span> <span class="n">df</span>
    
    <span class="c1"># Apply all functions
</span>    <span class="k">def</span> <span class="nf">process</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">df_list_out</span> <span class="o">=</span> <span class="p">[]</span>
        
        <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">df_list</span><span class="p">:</span>
            <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">remap_column_names</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
            <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">drop_columns</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
            <span class="n">df</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">add_region_column</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
            <span class="n">df_list_out</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">df_list_out</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">column_cleaner</span> <span class="o">=</span> <span class="n">ColumnCleaner</span><span class="p">([</span><span class="n">data_happiness_2015</span><span class="p">,</span> <span class="n">data_happiness_2016</span><span class="p">,</span> <span class="n">data_happiness_2017</span><span class="p">,</span> 
                               <span class="n">data_happiness_2018</span><span class="p">,</span> <span class="n">data_happiness_2019</span><span class="p">,</span> <span class="n">data_happiness_2020</span><span class="p">],</span> <span class="n">region_mapping</span><span class="p">)</span>
<span class="n">data_new</span> <span class="o">=</span> <span class="n">column_cleaner</span><span class="p">.</span><span class="n">process</span><span class="p">()</span>

<span class="c1"># Add a "Year" column to facilitate temporal analysis on the merged dataset
</span><span class="n">data_new</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="s">"Year"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2015</span>
<span class="n">data_new</span><span class="p">[</span><span class="mi">1</span><span class="p">][</span><span class="s">"Year"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2016</span>
<span class="n">data_new</span><span class="p">[</span><span class="mi">2</span><span class="p">][</span><span class="s">"Year"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2017</span>
<span class="n">data_new</span><span class="p">[</span><span class="mi">3</span><span class="p">][</span><span class="s">"Year"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2018</span>
<span class="n">data_new</span><span class="p">[</span><span class="mi">4</span><span class="p">][</span><span class="s">"Year"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2019</span>
<span class="n">data_new</span><span class="p">[</span><span class="mi">5</span><span class="p">][</span><span class="s">"Year"</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2020</span>
</code></pre></div></div>

<p>Let’s now make sure that the column names are renamed, and that only the columns we care about are there:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data_new</span><span class="p">)):</span>
    <span class="n">column_names_previous</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">data_new</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">].</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">column_names_current</span> <span class="o">=</span> <span class="nb">set</span><span class="p">(</span><span class="n">data_new</span><span class="p">[</span><span class="n">i</span><span class="p">].</span><span class="n">columns</span><span class="p">)</span>
    <span class="k">assert</span> <span class="n">column_names_previous</span> <span class="o">==</span> <span class="n">column_names_current</span>
</code></pre></div></div>

<h3 id="column-values-scales">Column values scales</h3>

<p>Great! Looks like the column names are standardized, and the column sets constant across datasets. Did we miss anything?</p>

<p>We did. When merging datasets generated at different points in time, it’s crucial to ask yourself: are the variables measured on identical scales across time? Let’s compare data from 2015 and 2020:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_new</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>158.000000</td>
      <td>158.000000</td>
      <td>158.000000</td>
      <td>158.000000</td>
      <td>158.000000</td>
      <td>158.000000</td>
      <td>158.000000</td>
      <td>158.0</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>5.375734</td>
      <td>0.846137</td>
      <td>0.991046</td>
      <td>0.630259</td>
      <td>0.428615</td>
      <td>0.143422</td>
      <td>0.237296</td>
      <td>2015.0</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.145010</td>
      <td>0.403121</td>
      <td>0.272369</td>
      <td>0.247078</td>
      <td>0.150693</td>
      <td>0.120034</td>
      <td>0.126685</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.839000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2015.0</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>4.526000</td>
      <td>0.545808</td>
      <td>0.856823</td>
      <td>0.439185</td>
      <td>0.328330</td>
      <td>0.061675</td>
      <td>0.150553</td>
      <td>2015.0</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>5.232500</td>
      <td>0.910245</td>
      <td>1.029510</td>
      <td>0.696705</td>
      <td>0.435515</td>
      <td>0.107220</td>
      <td>0.216130</td>
      <td>2015.0</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.243750</td>
      <td>1.158448</td>
      <td>1.214405</td>
      <td>0.811013</td>
      <td>0.549092</td>
      <td>0.180255</td>
      <td>0.309882</td>
      <td>2015.0</td>
    </tr>
    <tr>
      <th>max</th>
      <td>7.587000</td>
      <td>1.690420</td>
      <td>1.402230</td>
      <td>1.025250</td>
      <td>0.669730</td>
      <td>0.551910</td>
      <td>0.795880</td>
      <td>2015.0</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_new</span><span class="p">[</span><span class="mi">5</span><span class="p">].</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Generosity</th>
      <th>Trust</th>
      <th>Year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>153.00000</td>
      <td>153.000000</td>
      <td>153.000000</td>
      <td>153.000000</td>
      <td>153.000000</td>
      <td>153.000000</td>
      <td>153.000000</td>
      <td>153.0</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>5.47324</td>
      <td>9.295706</td>
      <td>0.808721</td>
      <td>64.445529</td>
      <td>0.783360</td>
      <td>-0.014568</td>
      <td>0.733120</td>
      <td>2020.0</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.11227</td>
      <td>1.201588</td>
      <td>0.121453</td>
      <td>7.057848</td>
      <td>0.117786</td>
      <td>0.151809</td>
      <td>0.175172</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.56690</td>
      <td>6.492642</td>
      <td>0.319460</td>
      <td>45.200001</td>
      <td>0.396573</td>
      <td>-0.300907</td>
      <td>0.109784</td>
      <td>2020.0</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>4.72410</td>
      <td>8.350645</td>
      <td>0.737217</td>
      <td>58.961712</td>
      <td>0.714839</td>
      <td>-0.127015</td>
      <td>0.683019</td>
      <td>2020.0</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>5.51500</td>
      <td>9.456313</td>
      <td>0.829204</td>
      <td>66.305145</td>
      <td>0.799805</td>
      <td>-0.033665</td>
      <td>0.783122</td>
      <td>2020.0</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.22850</td>
      <td>10.265124</td>
      <td>0.906747</td>
      <td>69.289192</td>
      <td>0.877709</td>
      <td>0.085429</td>
      <td>0.849151</td>
      <td>2020.0</td>
    </tr>
    <tr>
      <th>max</th>
      <td>7.80870</td>
      <td>11.450681</td>
      <td>0.974670</td>
      <td>76.804581</td>
      <td>0.974998</td>
      <td>0.560664</td>
      <td>0.935585</td>
      <td>2020.0</td>
    </tr>
  </tbody>
</table>
</div>

<p>Note that all variables from the 2015 dataset (except for Happiness) have a minimum value of 0, and varying max values (even &gt; 1). On the other hand, no variables from 2020 have a min = 0, and some even have negative minimum values! This suggests that either the data collection process was different, or that some modification was (wasn’t?) done to the data after it was collected.</p>

<p>What can be done about this? The safest approach would be to discard the dataset, since we don’t know if data collection methods were the same. Another option is to scale the variables to range 0-1 instead. A potential disadvantage is that the original variables’ values might have shifted over time, and standardizing each dataset to be in the 0-1 range could remove information about such shifts.</p>

<p>The <a href="https://happiness-report.s3.amazonaws.com/2020/WHR20_Ch2_Statistical_Appendix.pdf">Statistical Appendix</a> for the 2020 dataset explains the ranges and meanings of values for each column. However, there seem to be some discrepancies between the appendix and values of columns for 2015 - 2019 datasets, e.g. the “Family” column is missing from the Appendix. Moreover, the “Health” column has fractional values roughly in the range 0 - 1, while the Appendix states that these values should measure the life expectancy in years.</p>

<p>Based on the above caveats, it will be safest to discard the 2020 dataset and merge the 2015 - 2019 datasets without any modifications in variable values, as it seems that they are measured on the same scales.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Exclude the 2020 dataset
</span><span class="n">data_new</span> <span class="o">=</span> <span class="n">data_new</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">concat</span><span class="p">(</span><span class="n">data_new</span><span class="p">)</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>782.000000</td>
      <td>782.000000</td>
      <td>782.000000</td>
      <td>782.000000</td>
      <td>782.000000</td>
      <td>781.000000</td>
      <td>782.000000</td>
      <td>782.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>5.379018</td>
      <td>0.916047</td>
      <td>1.078392</td>
      <td>0.612416</td>
      <td>0.411091</td>
      <td>0.125436</td>
      <td>0.218576</td>
      <td>2016.993606</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.127456</td>
      <td>0.407340</td>
      <td>0.329548</td>
      <td>0.248309</td>
      <td>0.152880</td>
      <td>0.105816</td>
      <td>0.122321</td>
      <td>1.417364</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.693000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2015.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>4.509750</td>
      <td>0.606500</td>
      <td>0.869363</td>
      <td>0.440183</td>
      <td>0.309767</td>
      <td>0.054000</td>
      <td>0.130000</td>
      <td>2016.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>5.322000</td>
      <td>0.982205</td>
      <td>1.124735</td>
      <td>0.647310</td>
      <td>0.431000</td>
      <td>0.091000</td>
      <td>0.201982</td>
      <td>2017.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.189500</td>
      <td>1.236187</td>
      <td>1.327250</td>
      <td>0.808000</td>
      <td>0.531000</td>
      <td>0.156030</td>
      <td>0.278832</td>
      <td>2018.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>7.769000</td>
      <td>2.096000</td>
      <td>1.644000</td>
      <td>1.141000</td>
      <td>0.724000</td>
      <td>0.551910</td>
      <td>0.838075</td>
      <td>2019.000000</td>
    </tr>
  </tbody>
</table>
</div>

<h3 id="missing-values">Missing values</h3>

<p>Looks like the happiness data got merged successfully! Let’s now quickly look at whether there are any NA values, most likely due to mapping country names to region names:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">isna</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Country        0
Happiness      0
GDP            0
Family         0
Health         0
Freedom        0
Trust          1
Generosity     0
Region        25
Year           0
dtype: int64
</code></pre></div></div>

<p>As suspected, we have 25 rows with NA values in the “Region” column. What are these?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">isna</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Country        0
Happiness      0
GDP            0
Family         0
Health         0
Freedom        0
Trust          1
Generosity     0
Region        25
Year           0
dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span><span class="p">[</span><span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">isna</span><span class="p">().</span><span class="nb">any</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)]</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Region</th>
      <th>Year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>21</th>
      <td>Oman</td>
      <td>6.853</td>
      <td>1.360110</td>
      <td>1.081820</td>
      <td>0.762760</td>
      <td>0.632740</td>
      <td>0.325240</td>
      <td>0.215420</td>
      <td>NaN</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>90</th>
      <td>Somaliland region</td>
      <td>5.057</td>
      <td>0.188470</td>
      <td>0.951520</td>
      <td>0.438730</td>
      <td>0.465820</td>
      <td>0.399280</td>
      <td>0.503180</td>
      <td>NaN</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>93</th>
      <td>Mozambique</td>
      <td>4.971</td>
      <td>0.083080</td>
      <td>1.026260</td>
      <td>0.091310</td>
      <td>0.340370</td>
      <td>0.156030</td>
      <td>0.222690</td>
      <td>NaN</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>96</th>
      <td>Lesotho</td>
      <td>4.898</td>
      <td>0.375450</td>
      <td>1.041030</td>
      <td>0.076120</td>
      <td>0.317670</td>
      <td>0.125040</td>
      <td>0.163880</td>
      <td>NaN</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>100</th>
      <td>Swaziland</td>
      <td>4.867</td>
      <td>0.712060</td>
      <td>1.072840</td>
      <td>0.075660</td>
      <td>0.306580</td>
      <td>0.030600</td>
      <td>0.182590</td>
      <td>NaN</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>125</th>
      <td>Djibouti</td>
      <td>4.369</td>
      <td>0.440250</td>
      <td>0.592070</td>
      <td>0.362910</td>
      <td>0.460740</td>
      <td>0.281050</td>
      <td>0.180930</td>
      <td>NaN</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>147</th>
      <td>Central African Republic</td>
      <td>3.678</td>
      <td>0.078500</td>
      <td>0.000000</td>
      <td>0.066990</td>
      <td>0.488790</td>
      <td>0.082890</td>
      <td>0.238350</td>
      <td>NaN</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>32</th>
      <td>Taiwan Province of China</td>
      <td>6.422</td>
      <td>1.433627</td>
      <td>1.384565</td>
      <td>0.793984</td>
      <td>0.361467</td>
      <td>0.063829</td>
      <td>0.258360</td>
      <td>NaN</td>
      <td>2017</td>
    </tr>
    <tr>
      <th>70</th>
      <td>Hong Kong S.A.R., China</td>
      <td>5.472</td>
      <td>1.551675</td>
      <td>1.262791</td>
      <td>0.943062</td>
      <td>0.490969</td>
      <td>0.293934</td>
      <td>0.374466</td>
      <td>NaN</td>
      <td>2017</td>
    </tr>
    <tr>
      <th>112</th>
      <td>Mozambique</td>
      <td>4.550</td>
      <td>0.234306</td>
      <td>0.870701</td>
      <td>0.106654</td>
      <td>0.480791</td>
      <td>0.179436</td>
      <td>0.322228</td>
      <td>NaN</td>
      <td>2017</td>
    </tr>
    <tr>
      <th>138</th>
      <td>Lesotho</td>
      <td>3.808</td>
      <td>0.521021</td>
      <td>1.190095</td>
      <td>0.000000</td>
      <td>0.390661</td>
      <td>0.119095</td>
      <td>0.157497</td>
      <td>NaN</td>
      <td>2017</td>
    </tr>
    <tr>
      <th>154</th>
      <td>Central African Republic</td>
      <td>2.693</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.018773</td>
      <td>0.270842</td>
      <td>0.056565</td>
      <td>0.280876</td>
      <td>NaN</td>
      <td>2017</td>
    </tr>
    <tr>
      <th>19</th>
      <td>United Arab Emirates</td>
      <td>6.774</td>
      <td>2.096000</td>
      <td>0.776000</td>
      <td>0.670000</td>
      <td>0.284000</td>
      <td>NaN</td>
      <td>0.186000</td>
      <td>Middle East and Northern Africa</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>37</th>
      <td>Trinidad &amp; Tobago</td>
      <td>6.192</td>
      <td>1.223000</td>
      <td>1.492000</td>
      <td>0.564000</td>
      <td>0.575000</td>
      <td>0.019000</td>
      <td>0.171000</td>
      <td>NaN</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>57</th>
      <td>Northern Cyprus</td>
      <td>5.835</td>
      <td>1.229000</td>
      <td>1.211000</td>
      <td>0.909000</td>
      <td>0.495000</td>
      <td>0.154000</td>
      <td>0.179000</td>
      <td>NaN</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>122</th>
      <td>Mozambique</td>
      <td>4.417</td>
      <td>0.198000</td>
      <td>0.902000</td>
      <td>0.173000</td>
      <td>0.531000</td>
      <td>0.158000</td>
      <td>0.206000</td>
      <td>NaN</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>140</th>
      <td>Lesotho</td>
      <td>3.808</td>
      <td>0.472000</td>
      <td>1.215000</td>
      <td>0.079000</td>
      <td>0.423000</td>
      <td>0.112000</td>
      <td>0.116000</td>
      <td>NaN</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>154</th>
      <td>Central African Republic</td>
      <td>3.083</td>
      <td>0.024000</td>
      <td>0.000000</td>
      <td>0.010000</td>
      <td>0.305000</td>
      <td>0.038000</td>
      <td>0.218000</td>
      <td>NaN</td>
      <td>2018</td>
    </tr>
    <tr>
      <th>38</th>
      <td>Trinidad &amp; Tobago</td>
      <td>6.192</td>
      <td>1.231000</td>
      <td>1.477000</td>
      <td>0.713000</td>
      <td>0.489000</td>
      <td>0.016000</td>
      <td>0.185000</td>
      <td>NaN</td>
      <td>2019</td>
    </tr>
    <tr>
      <th>63</th>
      <td>Northern Cyprus</td>
      <td>5.718</td>
      <td>1.263000</td>
      <td>1.252000</td>
      <td>1.042000</td>
      <td>0.417000</td>
      <td>0.162000</td>
      <td>0.191000</td>
      <td>NaN</td>
      <td>2019</td>
    </tr>
    <tr>
      <th>83</th>
      <td>North Macedonia</td>
      <td>5.274</td>
      <td>0.983000</td>
      <td>1.294000</td>
      <td>0.838000</td>
      <td>0.345000</td>
      <td>0.034000</td>
      <td>0.185000</td>
      <td>NaN</td>
      <td>2019</td>
    </tr>
    <tr>
      <th>119</th>
      <td>Gambia</td>
      <td>4.516</td>
      <td>0.308000</td>
      <td>0.939000</td>
      <td>0.428000</td>
      <td>0.382000</td>
      <td>0.167000</td>
      <td>0.269000</td>
      <td>NaN</td>
      <td>2019</td>
    </tr>
    <tr>
      <th>122</th>
      <td>Mozambique</td>
      <td>4.466</td>
      <td>0.204000</td>
      <td>0.986000</td>
      <td>0.390000</td>
      <td>0.494000</td>
      <td>0.138000</td>
      <td>0.197000</td>
      <td>NaN</td>
      <td>2019</td>
    </tr>
    <tr>
      <th>134</th>
      <td>Swaziland</td>
      <td>4.212</td>
      <td>0.811000</td>
      <td>1.149000</td>
      <td>0.000000</td>
      <td>0.313000</td>
      <td>0.135000</td>
      <td>0.074000</td>
      <td>NaN</td>
      <td>2019</td>
    </tr>
    <tr>
      <th>143</th>
      <td>Lesotho</td>
      <td>3.802</td>
      <td>0.489000</td>
      <td>1.169000</td>
      <td>0.168000</td>
      <td>0.359000</td>
      <td>0.093000</td>
      <td>0.107000</td>
      <td>NaN</td>
      <td>2019</td>
    </tr>
    <tr>
      <th>154</th>
      <td>Central African Republic</td>
      <td>3.083</td>
      <td>0.026000</td>
      <td>0.000000</td>
      <td>0.105000</td>
      <td>0.225000</td>
      <td>0.035000</td>
      <td>0.235000</td>
      <td>NaN</td>
      <td>2019</td>
    </tr>
  </tbody>
</table>
</div>

<p>Since there are only 25 rows, we can fix these missing value manually:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span><span class="p">[</span><span class="s">"Region"</span><span class="p">].</span><span class="n">unique</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>array(['Western Europe', 'North America', 'Australia and New Zealand',
       'Middle East and Northern Africa', 'Latin America and Caribbean',
       nan, 'Southeastern Asia', 'Central and Eastern Europe',
       'Eastern Asia', 'Sub-Saharan Africa', 'Southern Asia'],
      dtype=object)
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">21</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Middle East and Northern Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">90</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">93</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">96</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">100</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">125</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">147</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">32</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Eastern Asia"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">70</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Eastern Asia"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">112</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">138</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">154</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">19</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Middle East and Northern Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">37</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">57</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Central and Eastern Europe"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">122</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">140</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">154</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">38</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">63</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Central and Eastern Europe"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">83</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Central and Eastern Europe"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">119</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">122</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">134</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">143</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">154</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">]</span> <span class="o">=</span> <span class="s">"Sub-Saharan Africa"</span>
</code></pre></div></div>

<p>Let’s check the remaining NA values:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">isna</span><span class="p">().</span><span class="nb">sum</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Country       0
Happiness     0
GDP           0
Family        0
Health        0
Freedom       0
Trust         1
Generosity    0
Region        0
Year          0
dtype: int64
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span><span class="p">[</span><span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">isna</span><span class="p">().</span><span class="nb">any</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)]</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Region</th>
      <th>Year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19</th>
      <td>United Arab Emirates</td>
      <td>6.774</td>
      <td>2.096</td>
      <td>0.776</td>
      <td>0.67</td>
      <td>0.284</td>
      <td>NaN</td>
      <td>0.186</td>
      <td>Middle East and Northern Africa</td>
      <td>2018</td>
    </tr>
  </tbody>
</table>
</div>

<p>To preserve data for temporal analysis, let’s impute the missing “Trust” value with mean values from other years for UAE:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">mean_trust_uae</span> <span class="o">=</span> <span class="nb">round</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">[</span><span class="n">data_happiness_concat</span><span class="p">[</span><span class="s">"Country"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"United Arab Emirates"</span><span class="p">][</span><span class="s">"Trust"</span><span class="p">]),</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">19</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">]</span> <span class="o">=</span> <span class="n">mean_trust_uae</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">19</span><span class="p">]]</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Region</th>
      <th>Year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>19</th>
      <td>United Arab Emirates</td>
      <td>6.901</td>
      <td>1.42727</td>
      <td>1.12575</td>
      <td>0.80925</td>
      <td>0.64157</td>
      <td>0.312</td>
      <td>0.26428</td>
      <td>Middle East and Northern Africa</td>
      <td>2015</td>
    </tr>
  </tbody>
</table>
</div>

<p>At this point, the merged happiness dataset looks fairly decent! Let’s move on to see how we can merge the suicide dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_suicide</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s">"data/suicide_rates_overview/master.csv"</span><span class="p">)</span>
<span class="n">data_suicide</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country</th>
      <th>year</th>
      <th>sex</th>
      <th>age</th>
      <th>suicides_no</th>
      <th>population</th>
      <th>suicides/100k pop</th>
      <th>country-year</th>
      <th>HDI for year</th>
      <th>gdp_for_year ($)</th>
      <th>gdp_per_capita ($)</th>
      <th>generation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Albania</td>
      <td>1987</td>
      <td>male</td>
      <td>15-24 years</td>
      <td>21</td>
      <td>312900</td>
      <td>6.71</td>
      <td>Albania1987</td>
      <td>NaN</td>
      <td>2,156,624,900</td>
      <td>796</td>
      <td>Generation X</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Albania</td>
      <td>1987</td>
      <td>male</td>
      <td>35-54 years</td>
      <td>16</td>
      <td>308000</td>
      <td>5.19</td>
      <td>Albania1987</td>
      <td>NaN</td>
      <td>2,156,624,900</td>
      <td>796</td>
      <td>Silent</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Albania</td>
      <td>1987</td>
      <td>female</td>
      <td>15-24 years</td>
      <td>14</td>
      <td>289700</td>
      <td>4.83</td>
      <td>Albania1987</td>
      <td>NaN</td>
      <td>2,156,624,900</td>
      <td>796</td>
      <td>Generation X</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Albania</td>
      <td>1987</td>
      <td>male</td>
      <td>75+ years</td>
      <td>1</td>
      <td>21800</td>
      <td>4.59</td>
      <td>Albania1987</td>
      <td>NaN</td>
      <td>2,156,624,900</td>
      <td>796</td>
      <td>G.I. Generation</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Albania</td>
      <td>1987</td>
      <td>male</td>
      <td>25-34 years</td>
      <td>9</td>
      <td>274300</td>
      <td>3.28</td>
      <td>Albania1987</td>
      <td>NaN</td>
      <td>2,156,624,900</td>
      <td>796</td>
      <td>Boomers</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_suicide</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>year</th>
      <th>suicides_no</th>
      <th>population</th>
      <th>suicides/100k pop</th>
      <th>HDI for year</th>
      <th>gdp_per_capita ($)</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>27820.000000</td>
      <td>27820.000000</td>
      <td>2.782000e+04</td>
      <td>27820.000000</td>
      <td>8364.000000</td>
      <td>27820.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2001.258375</td>
      <td>242.574407</td>
      <td>1.844794e+06</td>
      <td>12.816097</td>
      <td>0.776601</td>
      <td>16866.464414</td>
    </tr>
    <tr>
      <th>std</th>
      <td>8.469055</td>
      <td>902.047917</td>
      <td>3.911779e+06</td>
      <td>18.961511</td>
      <td>0.093367</td>
      <td>18887.576472</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1985.000000</td>
      <td>0.000000</td>
      <td>2.780000e+02</td>
      <td>0.000000</td>
      <td>0.483000</td>
      <td>251.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>1995.000000</td>
      <td>3.000000</td>
      <td>9.749850e+04</td>
      <td>0.920000</td>
      <td>0.713000</td>
      <td>3447.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>2002.000000</td>
      <td>25.000000</td>
      <td>4.301500e+05</td>
      <td>5.990000</td>
      <td>0.779000</td>
      <td>9372.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>2008.000000</td>
      <td>131.000000</td>
      <td>1.486143e+06</td>
      <td>16.620000</td>
      <td>0.855000</td>
      <td>24874.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>2016.000000</td>
      <td>22338.000000</td>
      <td>4.380521e+07</td>
      <td>224.970000</td>
      <td>0.944000</td>
      <td>126352.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>It seems like the “HDI for year” column might have most or all empty values, let’s check this:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">data_suicide</span><span class="p">[</span><span class="s">"HDI for year"</span><span class="p">].</span><span class="n">isna</span><span class="p">())</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.699352983465133
</code></pre></div></div>

<p>Almost 70% of values are NA - let’s drop this column:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_suicide</span> <span class="o">=</span> <span class="n">data_suicide</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">"HDI for year"</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>We can also remove the “country-year” column, as it’s just a concatenation of the “country” and “year” columns:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_suicide</span> <span class="o">=</span> <span class="n">data_suicide</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">"country-year"</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>The biggest drawback of this dataset is that there is only two years of overlap with the happiness data: 2015 and 2016. Therefore, while we can still proceed with the analysis, we will have to break it down into two aspects:</p>

<ol>
  <li>Temporal analysis of happiness data using the merged happiness dataset</li>
  <li>Analysis of happiness + suicide data using a merged 2015/2016 happiness + 2015/2016 suicide dataset</li>
</ol>

<p>Let’s first see how much data from each year we have for the suicide dataset:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_suicide</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">"year"</span><span class="p">).</span><span class="n">count</span><span class="p">().</span><span class="n">tail</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>country</th>
      <th>sex</th>
      <th>age</th>
      <th>suicides_no</th>
      <th>population</th>
      <th>suicides/100k pop</th>
      <th>gdp_for_year ($)</th>
      <th>gdp_per_capita ($)</th>
      <th>generation</th>
    </tr>
    <tr>
      <th>year</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>2015</th>
      <td>744</td>
      <td>744</td>
      <td>744</td>
      <td>744</td>
      <td>744</td>
      <td>744</td>
      <td>744</td>
      <td>744</td>
      <td>744</td>
    </tr>
    <tr>
      <th>2016</th>
      <td>160</td>
      <td>160</td>
      <td>160</td>
      <td>160</td>
      <td>160</td>
      <td>160</td>
      <td>160</td>
      <td>160</td>
      <td>160</td>
    </tr>
  </tbody>
</table>
</div>

<p>Since we have only 160 rows for year 2016, compared to 744 for 2015, let’s drop rows for 2016 and drop some columns to simplify later analysis:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_suicide</span> <span class="o">=</span> <span class="n">data_suicide</span><span class="p">[</span><span class="n">data_suicide</span><span class="p">[</span><span class="s">"year"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2015</span><span class="p">]</span>
<span class="n">data_suicide_2015</span> <span class="o">=</span> <span class="n">data_suicide</span><span class="p">[</span><span class="n">data_suicide</span><span class="p">[</span><span class="s">"year"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2015</span><span class="p">]</span>
<span class="n">data_suicide_2015</span> <span class="o">=</span> <span class="n">data_suicide_2015</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">"sex"</span><span class="p">,</span> <span class="s">"age"</span><span class="p">,</span> <span class="s">"generation"</span><span class="p">,</span> <span class="s">" gdp_for_year ($) "</span><span class="p">,</span> <span class="s">"gdp_per_capita ($)"</span><span class="p">],</span> <span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div>

<p>We dropped columns like “age” and “sex” to simplify the dataset. Therefore, we now need to sum up / average multiple rows for each country on a per-country basis:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">suicides_no_sum</span> <span class="o">=</span> <span class="n">data_suicide_2015</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">"country"</span><span class="p">)[</span><span class="s">"suicides_no"</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span>
<span class="n">population_sum</span> <span class="o">=</span> <span class="n">data_suicide_2015</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">"country"</span><span class="p">)[</span><span class="s">"population"</span><span class="p">].</span><span class="nb">sum</span><span class="p">()</span>
<span class="n">suicides_100k_pop_mean</span> <span class="o">=</span> <span class="n">data_suicide_2015</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">"country"</span><span class="p">)[</span><span class="s">"suicides/100k pop"</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
<span class="n">data_suicide_2015_agg</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">({</span><span class="s">"Country"</span><span class="p">:</span> <span class="n">suicides_no_sum</span><span class="p">.</span><span class="n">index</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">:</span> <span class="mi">2015</span><span class="p">,</span> <span class="s">"Suicides_no"</span><span class="p">:</span> <span class="n">suicides_no_sum</span><span class="p">,</span> <span class="s">"Population"</span><span class="p">:</span> <span class="n">population_sum</span><span class="p">,</span> <span class="s">"Suicides_per_100k"</span><span class="p">:</span> <span class="n">suicides_100k_pop_mean</span><span class="p">})</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_suicide_2015_agg</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Year</th>
      <th>Suicides_no</th>
      <th>Population</th>
      <th>Suicides_per_100k</th>
    </tr>
    <tr>
      <th>country</th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
      <th></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>Antigua and Barbuda</th>
      <td>Antigua and Barbuda</td>
      <td>2015</td>
      <td>1</td>
      <td>91889</td>
      <td>1.301667</td>
    </tr>
    <tr>
      <th>Argentina</th>
      <td>Argentina</td>
      <td>2015</td>
      <td>3073</td>
      <td>39699624</td>
      <td>9.344167</td>
    </tr>
    <tr>
      <th>Armenia</th>
      <td>Armenia</td>
      <td>2015</td>
      <td>74</td>
      <td>2795335</td>
      <td>3.773333</td>
    </tr>
    <tr>
      <th>Australia</th>
      <td>Australia</td>
      <td>2015</td>
      <td>3027</td>
      <td>22240785</td>
      <td>12.848333</td>
    </tr>
    <tr>
      <th>Austria</th>
      <td>Austria</td>
      <td>2015</td>
      <td>1251</td>
      <td>8219386</td>
      <td>16.218333</td>
    </tr>
  </tbody>
</table>
</div>

<h2 id="data-merging">Data merging</h2>

<p>Let’s now merge the 2015 suicide data with the 2015 happiness data:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_2015</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">[</span><span class="n">data_happiness_concat</span><span class="p">[</span><span class="s">"Year"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2015</span><span class="p">]</span>
<span class="n">data_happiness_suicide</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">data_happiness_2015</span><span class="p">,</span> <span class="n">data_suicide_2015_agg</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="s">"left"</span><span class="p">,</span> <span class="n">left_on</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Country"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">],</span> <span class="n">right_on</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Country"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">])</span>
<span class="n">data_happiness_suicide</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Region</th>
      <th>Year</th>
      <th>Suicides_no</th>
      <th>Population</th>
      <th>Suicides_per_100k</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Switzerland</td>
      <td>7.587</td>
      <td>1.39651</td>
      <td>1.34951</td>
      <td>0.94143</td>
      <td>0.66557</td>
      <td>0.41978</td>
      <td>0.29678</td>
      <td>Western Europe</td>
      <td>2015</td>
      <td>1073.0</td>
      <td>7892502.0</td>
      <td>13.721667</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Iceland</td>
      <td>7.561</td>
      <td>1.30232</td>
      <td>1.40223</td>
      <td>0.94784</td>
      <td>0.62877</td>
      <td>0.14145</td>
      <td>0.43630</td>
      <td>Western Europe</td>
      <td>2015</td>
      <td>40.0</td>
      <td>308554.0</td>
      <td>11.720833</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Denmark</td>
      <td>7.527</td>
      <td>1.32548</td>
      <td>1.36058</td>
      <td>0.87464</td>
      <td>0.64938</td>
      <td>0.48357</td>
      <td>0.34139</td>
      <td>Western Europe</td>
      <td>2015</td>
      <td>564.0</td>
      <td>5383060.0</td>
      <td>10.118333</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Norway</td>
      <td>7.522</td>
      <td>1.45900</td>
      <td>1.33095</td>
      <td>0.88521</td>
      <td>0.66973</td>
      <td>0.36503</td>
      <td>0.34699</td>
      <td>Western Europe</td>
      <td>2015</td>
      <td>590.0</td>
      <td>4882909.0</td>
      <td>11.369167</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Canada</td>
      <td>7.427</td>
      <td>1.32629</td>
      <td>1.32261</td>
      <td>0.90563</td>
      <td>0.63297</td>
      <td>0.32957</td>
      <td>0.45811</td>
      <td>North America</td>
      <td>2015</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>

<p>We might have gotten some NA rows due to some missing countries in either dataset, so let’s check what these are:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_suicide</span><span class="p">[</span><span class="n">data_happiness_suicide</span><span class="p">.</span><span class="n">isna</span><span class="p">().</span><span class="nb">any</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)].</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Region</th>
      <th>Year</th>
      <th>Suicides_no</th>
      <th>Population</th>
      <th>Suicides_per_100k</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>4</th>
      <td>Canada</td>
      <td>7.427</td>
      <td>1.32629</td>
      <td>1.32261</td>
      <td>0.90563</td>
      <td>0.63297</td>
      <td>0.32957</td>
      <td>0.45811</td>
      <td>North America</td>
      <td>2015</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>8</th>
      <td>New Zealand</td>
      <td>7.286</td>
      <td>1.25018</td>
      <td>1.31967</td>
      <td>0.90837</td>
      <td>0.63938</td>
      <td>0.42922</td>
      <td>0.47501</td>
      <td>Australia and New Zealand</td>
      <td>2015</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>11</th>
      <td>Costa Rica</td>
      <td>7.226</td>
      <td>0.95578</td>
      <td>1.23788</td>
      <td>0.86027</td>
      <td>0.63376</td>
      <td>0.10583</td>
      <td>0.25497</td>
      <td>Latin America and Caribbean</td>
      <td>2015</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>17</th>
      <td>Ireland</td>
      <td>6.940</td>
      <td>1.33596</td>
      <td>1.36948</td>
      <td>0.89533</td>
      <td>0.61777</td>
      <td>0.28703</td>
      <td>0.45901</td>
      <td>Western Europe</td>
      <td>2015</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
    <tr>
      <th>19</th>
      <td>United Arab Emirates</td>
      <td>6.901</td>
      <td>1.42727</td>
      <td>1.12575</td>
      <td>0.80925</td>
      <td>0.64157</td>
      <td>0.31200</td>
      <td>0.26428</td>
      <td>Middle East and Northern Africa</td>
      <td>2015</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
    </tr>
  </tbody>
</table>
</div>

<p>Indeed, we see that some countries from the happiness dataset were missing in the suicide dataset. Let’s drop these rows:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_suicide</span> <span class="o">=</span> <span class="n">data_happiness_suicide</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">axis</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">data_happiness_suicide</span><span class="p">.</span><span class="n">shape</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>(53, 13)
</code></pre></div></div>

<p>This leaves us with 53 complete rows of data.</p>

<h2 id="summary">Summary</h2>

<p>In summary, we performed the following transformations on both datasets:</p>

<ol>
  <li>Cleaned up column names: dropped irrelevant columns, standardized column names</li>
  <li>Imputed / removed rows with missing values</li>
  <li>Merged the 2015 - 2019 happiness datasets into a single one</li>
  <li>Merged the 2015 happiness and 2015 suicide datasets into a single one</li>
</ol>

<p>A thorough data preparation process is crucial for ensuring the validity fo any conclusions drawn from the data. This makes it an extremely important, if sometimes tedious, process.</p>

<h1 id="exploratory-data-analysis">Exploratory data analysis</h1>

<p>Now that we’ve cleaned up the data, we can move on to the exciting part: exploration and visualization!</p>

<p>This section will be split into two parts, one for each dataset:</p>

<ol>
  <li>Temporal and spatial analysis of the 2015 - 2019 happiness dataset</li>
  <li>Spatial analysis of the 2015 happiness + suicide dataset</li>
</ol>

<h2 id="2015---2019-happiness-data-analysis">2015 - 2019 happiness data analysis</h2>

<h3 id="a-first-look-at-the-data">A first look at the data</h3>

<p>Let’s start by looking at how the data looks like after all the processing:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Region</th>
      <th>Year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Switzerland</td>
      <td>7.587</td>
      <td>1.39651</td>
      <td>1.34951</td>
      <td>0.94143</td>
      <td>0.66557</td>
      <td>0.41978</td>
      <td>0.29678</td>
      <td>Western Europe</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Iceland</td>
      <td>7.561</td>
      <td>1.30232</td>
      <td>1.40223</td>
      <td>0.94784</td>
      <td>0.62877</td>
      <td>0.14145</td>
      <td>0.43630</td>
      <td>Western Europe</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Denmark</td>
      <td>7.527</td>
      <td>1.32548</td>
      <td>1.36058</td>
      <td>0.87464</td>
      <td>0.64938</td>
      <td>0.48357</td>
      <td>0.34139</td>
      <td>Western Europe</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Norway</td>
      <td>7.522</td>
      <td>1.45900</td>
      <td>1.33095</td>
      <td>0.88521</td>
      <td>0.66973</td>
      <td>0.36503</td>
      <td>0.34699</td>
      <td>Western Europe</td>
      <td>2015</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Canada</td>
      <td>7.427</td>
      <td>1.32629</td>
      <td>1.32261</td>
      <td>0.90563</td>
      <td>0.63297</td>
      <td>0.32957</td>
      <td>0.45811</td>
      <td>North America</td>
      <td>2015</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Year</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>782.000000</td>
      <td>782.000000</td>
      <td>782.000000</td>
      <td>782.000000</td>
      <td>782.000000</td>
      <td>782.000000</td>
      <td>782.000000</td>
      <td>782.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>5.379018</td>
      <td>0.916047</td>
      <td>1.078392</td>
      <td>0.612416</td>
      <td>0.411091</td>
      <td>0.126174</td>
      <td>0.218576</td>
      <td>2016.993606</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.127456</td>
      <td>0.407340</td>
      <td>0.329548</td>
      <td>0.248309</td>
      <td>0.152880</td>
      <td>0.106015</td>
      <td>0.122321</td>
      <td>1.417364</td>
    </tr>
    <tr>
      <th>min</th>
      <td>2.693000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2015.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>4.509750</td>
      <td>0.606500</td>
      <td>0.869363</td>
      <td>0.440183</td>
      <td>0.309767</td>
      <td>0.055000</td>
      <td>0.130000</td>
      <td>2016.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>5.322000</td>
      <td>0.982205</td>
      <td>1.124735</td>
      <td>0.647310</td>
      <td>0.431000</td>
      <td>0.091895</td>
      <td>0.201982</td>
      <td>2017.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.189500</td>
      <td>1.236187</td>
      <td>1.327250</td>
      <td>0.808000</td>
      <td>0.531000</td>
      <td>0.157192</td>
      <td>0.278832</td>
      <td>2018.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>7.769000</td>
      <td>2.096000</td>
      <td>1.644000</td>
      <td>1.141000</td>
      <td>0.724000</td>
      <td>0.551910</td>
      <td>0.838075</td>
      <td>2019.000000</td>
    </tr>
  </tbody>
</table>
</div>

<p>There is a wide range of mean and std values for the variables. E.g. while Trust has only 0.1 std, GDP has over 0.4.</p>

<p>Let’s create a pairplot for a given year, say 2015, to get a better understanding of individual variables’ distributions, as well as relationship between them:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="n">sns</span>

<span class="n">sns</span><span class="p">.</span><span class="n">set_theme</span><span class="p">(</span><span class="s">"notebook"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pp</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">)</span>
<span class="n">pp</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">"Pairplot of happiness data for year 2015"</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.02</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.02, 'Pairplot of happiness data for year 2015')
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_82_1.png" alt="png" /></p>

<p>We can see that most variables have skewed distributions, and that there are some fairly apparent relationships between variables such as Health and GDP:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sp1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">"Health"</span><span class="p">,</span> <span class="n">line_kws</span> <span class="o">=</span> <span class="p">{</span><span class="s">"color"</span><span class="p">:</span> <span class="s">"red"</span><span class="p">})</span>
<span class="n">sp1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"GDP vs Health in 2015"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'GDP vs Health in 2015')
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_84_1.png" alt="png" /></p>

<h3 id="univariate-distributions">Univariate distributions</h3>

<p>Let’s look at how some variables’ distributions evolved over time:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_boxplot_over_time</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">variable_name_year</span><span class="p">,</span> <span class="n">variable_name_response</span><span class="p">):</span>
    <span class="n">bp</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">x</span> <span class="o">=</span> <span class="n">variable_name_year</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">variable_name_response</span><span class="p">,</span> <span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s">"box"</span><span class="p">)</span>
    <span class="n">bp</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"{} score distribution per year"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">variable_name_response</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Health
</span><span class="n">create_boxplot_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_88_0.png" alt="png" /></p>

<p>It seems that there was initially a decrease, followed by an increase in mean health scores over time.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Trust
</span><span class="n">create_boxplot_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_90_0.png" alt="png" /></p>

<p>Here, the story is quite different than for Health. Trust scores have seen a steady decline over time, reflecting decreasing institutional trust.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Freedom
</span><span class="n">create_boxplot_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_92_0.png" alt="png" /></p>

<p>Mean Freedom score values seem to oscillate over time - no clear trend.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Generosity
</span><span class="n">create_boxplot_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_94_0.png" alt="png" /></p>

<p>Here, we can see a fairly sharp, persisting drop in Generosity scores since 2018, indicating that people are giving away less money as donations e.g. to charities.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># GDP
</span><span class="n">create_boxplot_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_96_0.png" alt="png" /></p>

<p>The distribution of GDP scores seems fairly constant over time.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Family
</span><span class="n">create_boxplot_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_98_0.png" alt="png" /></p>

<p>For Family scores, there is a marked sharp drop in scores in 2016, followed by a large, persisting jump in 2017. We can only hypothesise what happened - perhaps data collection methods changed, or the question asked to participants was modified?</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Happiness
</span><span class="n">create_boxplot_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_100_0.png" alt="png" /></p>

<p>Finally, the variable that scores happiness, seems to have fairly unchanged distribution over time.</p>

<h3 id="bivariate-distributions">Bivariate distributions</h3>

<p>Now that we have a fairly good idea of distribution shifts over time for individual variables, let’s look at the relationships between pairs of variables, and how they changed:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">matplotlib</span> <span class="kn">import</span> <span class="n">animation</span>
<span class="c1"># from IPython.display import HTML
</span><span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>

<span class="k">def</span> <span class="nf">get_data_for_year</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">year</span><span class="p">):</span>
    <span class="c1"># Exclude year since it's a categorical variable
</span>    <span class="k">return</span> <span class="n">df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">"Year"</span><span class="p">]</span> <span class="o">==</span> <span class="n">year</span><span class="p">,</span> <span class="n">df</span><span class="p">.</span><span class="n">columns</span> <span class="o">!=</span> <span class="s">"Year"</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">create_pairwise_corrplot</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">year</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">data_title</span><span class="o">=</span><span class="s">"happiness"</span><span class="p">):</span>
    <span class="n">corr</span> <span class="o">=</span> <span class="n">get_data_for_year</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">year</span><span class="p">).</span><span class="n">corr</span><span class="p">()</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">triu</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">ones_like</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">dtype</span> <span class="o">=</span> <span class="nb">bool</span><span class="p">))</span>
    <span class="n">cmap</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">diverging_palette</span><span class="p">(</span><span class="mi">230</span><span class="p">,</span> <span class="mi">20</span><span class="p">,</span>  <span class="n">as_cmap</span> <span class="o">=</span> <span class="bp">True</span><span class="p">)</span>
    <span class="n">corrplot</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">heatmap</span><span class="p">(</span><span class="n">corr</span><span class="p">,</span> <span class="n">mask</span> <span class="o">=</span> <span class="n">mask</span><span class="p">,</span> <span class="n">cmap</span> <span class="o">=</span> <span class="n">cmap</span><span class="p">,</span> <span class="n">center</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">square</span> <span class="o">=</span> <span class="bp">True</span><span class="p">,</span> <span class="n">linewidths</span> <span class="o">=</span> <span class="mf">0.5</span><span class="p">,</span> <span class="n">vmin</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="n">vmax</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Pairwise correlation plot for {} {} data"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">year</span><span class="p">,</span> <span class="n">data_title</span><span class="p">))</span>
    
<span class="k">def</span> <span class="nf">animate</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">data_title</span><span class="o">=</span><span class="s">"happiness"</span><span class="p">):</span>
    <span class="n">year_list</span> <span class="o">=</span> <span class="p">[</span><span class="mi">2015</span><span class="p">,</span> <span class="mi">2016</span><span class="p">,</span> <span class="mi">2017</span><span class="p">,</span> <span class="mi">2018</span><span class="p">,</span> <span class="mi">2019</span><span class="p">]</span>
    <span class="n">create_pairwise_corrplot</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="n">year_list</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="n">data_title</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># fig, ax = plt.subplots()
# anim = animation.FuncAnimation(fig, animate, frames = len(data_happiness_concat["Year"].unique()))
# HTML(anim.to_html5_video())
</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">[</span><span class="s">"Year"</span><span class="p">].</span><span class="n">unique</span><span class="p">())):</span>
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">animate</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="s">"happiness"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_105_0.png" alt="png" /></p>

<p><img src="/images/happiness_files/happiness_105_1.png" alt="png" /></p>

<p><img src="/images/happiness_files/happiness_105_2.png" alt="png" /></p>

<p><img src="/images/happiness_files/happiness_105_3.png" alt="png" /></p>

<p><img src="/images/happiness_files/happiness_105_4.png" alt="png" /></p>

<p>Most correlations stay the same. It’s worth noting that variable most strongly positively correlated with Happiness are GDP, Family, and Health:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_scatterplot_kde_over_time</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">variable_name_year</span><span class="p">):</span>
    <span class="n">scatter</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="n">variable_name_year</span><span class="p">,</span> <span class="n">palette</span> <span class="o">=</span> <span class="s">"YlOrBr"</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">5</span><span class="p">)</span>
    <span class="n">kde</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="n">variable_name_year</span><span class="p">,</span> <span class="n">levels</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">palette</span> <span class="o">=</span> <span class="s">"YlOrBr"</span><span class="p">)</span>
    <span class="n">scatter</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"{} vs {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_scatterplot_kde_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_108_0.png" alt="png" /></p>

<p>Although it’s widely known “money won’t make you happy” (at least beyond a certain threshold, which in the US is estimated at ~ $85,000), our data seems to suggest a fairly strong <em>correlation</em> nevertheless. We need to be careful in drawing any conclusions, as GDP by itself likely doesn’t increase happiness. Instead it’s more likely that higher GDP increases happiness indirectly - having higher disposable income can <a href="https://www.becomingminimalist.com/experiences/">buy people experiences</a>, or allow for <a href="https://www.effectivealtruism.org/articles/introduction-to-effective-altruism/">effective altriusm</a> - both of which are proven to improve happiness.</p>

<p>This graph leads to 2 important conclusions:</p>

<ol>
  <li>In general, correlation != causation</li>
  <li>Having some domain knowledge helps understand relationships present in data.</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_scatterplot_kde_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_110_0.png" alt="png" /></p>

<p>Again, fairly strong positive correlation, with a shift towards higher family scores with time. Surprisingly, no corresponding increase in happiness scores, suggesting other factors contributed to its decline, balancing it out.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_scatterplot_kde_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_112_0.png" alt="png" /></p>

<p>This relationship is fairly self-explanatory and expected. High life expectancy is typically a result of caring about own health, and <a href="https://www.healthline.com/nutrition/happiness-and-health#TOC_TITLE_HDR_2">healthy people are more happy, on average</a>.</p>

<p>Interestingly, there are slight decreases in correlation between Generosity and GDP, Family, and Health. Let’s investigate these further:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_scatterplot_kde_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_115_0.png" alt="png" /></p>

<p>By creating a scatterplot with a Kernel Density Estimation plot overlaid on top, we can see the temporal shift in the bivariate distribution of Generosity and GDP. It seems that, over time, the distribution decreased its standard deviation, and shifted the mean to around (0.2, 1.0). How does this graph show that the correlation between Generosity and GDP decreased? The distribution is more “circular”, which weakens the correlation - it would reach 0 if the distribution was perfectly circular. This graphic illustrates it well:</p>

<p><img src="/images/happiness_files/correlation_bivariate.png" alt="" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_scatterplot_kde_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_117_0.png" alt="png" /></p>

<p>In terms of Generosity vs Family, we see an even bigger shift towards a smaller standard deviation, as well as a shift of distribution’s mean. Again, the indicator of weakened correlation are progressively more circular distributions.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_scatterplot_kde_over_time</span><span class="p">(</span><span class="n">data_happiness_concat</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_119_0.png" alt="png" /></p>

<p>As before, there is a decrease of standard deviation over time, as well as a shift towards the mean of around (0.2, 0.7). Once again, the distributions become more circular overtime, confirming the decreased correlation.</p>

<h3 id="spatiality-of-happiness-scores">Spatiality of happiness scores</h3>

<h4 id="average-happiness-scores-by-region">Average happiness scores by region</h4>

<p>After investigating the temporal aspect of happiness scores, let’s look closer at their spatiality. We begin with a summary of average happiness scores on a per-region basis:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_groupby_region_mean</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">"Region"</span><span class="p">).</span><span class="n">mean</span><span class="p">().</span><span class="n">sort_values</span><span class="p">(</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">bp1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_groupby_region_mean</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">"Region"</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s">"bar"</span><span class="p">)</span>
<span class="n">bp1</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Average happiness scores by region across 2015 - 2019"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'Average happiness scores by region across 2015 - 2019')
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_124_1.png" alt="png" /></p>

<p>We can see that, overall, regions with lower-developed countries tend to have lower happiness scores. This agrees with our preivous finding that Happiness schores are strongly correlated with GDP. However, there are some regions which don’t adhere to this trend strongly, such as Central and Eastern Europe. There is a marked difference between Happiness scores between Western and Central / Eastern Europe.</p>

<h4 id="change-of-happiness-scores-over-time">Change of happiness scores over time</h4>

<p>We will now investigate how these scores changed over time for each region:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_groupby_region_year_mean</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">"Region"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">]).</span><span class="n">mean</span><span class="p">().</span><span class="n">sort_values</span><span class="p">(</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="n">ascending</span> <span class="o">=</span> <span class="bp">False</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_groupby_region_year_mean</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s">"Year"</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">"Region"</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s">"point"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.FacetGrid at 0x7ff6ad26f8b0&gt;
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_128_1.png" alt="png" /></p>

<p>Interestingly, there seem to be three fairly distinct groups of regions with similar happiness scores. The first group, including Australia, North America, and Western Europe, notes the highest Happiness scores. While these scores increased in some regions, they decreased in others.</p>

<p>The second group has many more regions, and the trends are similar - some happiness scores decreased, while others increased over time. Notable, there was a large drop in 2016 followed by a recovery in the scores for Southeastern Asia.</p>

<p>Finally, the last group is comprised of Southern Asia and Sub-Saharan Africa. Happiness scores also didn’t change much, similarly to the other two groups.</p>

<p>While we’re on the topic of happiness score variabilities, it might be interesting to look at the degrees of homogeneity of Happiness scores within each region:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sp1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">"Region"</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s">"swarm"</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">8</span><span class="p">,</span> <span class="n">s</span> <span class="o">=</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">sp1</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Distribution of happiness scores per region across 2015 - 2019"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'Distribution of happiness scores per region across 2015 - 2019')
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_131_1.png" alt="png" /></p>

<p>There are several observations to note:</p>

<ol>
  <li>Regions with fewer countries tend to have somewhat lower variability of happiness scores</li>
  <li>Well-developed regions tend to have smaller variability of happiness scores compared to poorer regions</li>
</ol>

<p>The observation from point 1. might be purely due to chance - we wouldn’t have any specific reasons to believe that regions with fewer countries should be more homogenous in terms of happiness. However, the observation from point 2. might be due to the fact that, on average, well-developed regions like North America tend to provide a more “even” access to things that make people happier - healthcare systems, basic entertainment, infrastructure which allows to visit family members or see them virtually on a video chat, etc.</p>

<h4 id="variability-of-happiness-scores">Variability of happiness scores</h4>

<p>To formalize the notion of happiness score variability, and facilitate its temporal analysis, we can calculate the standard deviation of scores on a per-region basis:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_groupby_region_std</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">"Region"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">]).</span><span class="n">std</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
<span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_groupby_region_std</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s">"Year"</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">"Region"</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s">"point"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;seaborn.axisgrid.FacetGrid at 0x7ff6ad416430&gt;
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_135_1.png" alt="png" /></p>

<p>The evolution of standard deviation of happiness scores is pretty striking. While some regions, like the Middle East and Northern Africa, have consistently seen very high variability, other regions such as Australia and New Zealand have seen barely any!</p>

<p>Just via a visual inspection of the graph, we can again see an interesting relationship which we implicitly hypothesized about earlier, namely - that well-developed regions tend to have lower variability in happiness scores. Let’s confirm this by looking at the relationship of the standard deviation of happiness scores vs mean GDP for each region:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Merge dataframes to have both the mean and std values for each region
</span><span class="n">data_std_region_happiness</span> <span class="o">=</span> <span class="n">data_happiness_groupby_region_std</span><span class="p">[[</span><span class="s">"Region"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">]]</span>
<span class="n">data_std_region_happiness</span> <span class="o">=</span> <span class="n">data_std_region_happiness</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Happiness"</span><span class="p">:</span> <span class="s">"Happiness_mean"</span><span class="p">})</span>
<span class="n">data_mean_region_happiness</span> <span class="o">=</span> <span class="n">data_happiness_groupby_region_mean</span><span class="p">[[</span><span class="s">"Region"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">]]</span>
<span class="n">data_mean_region_happiness</span> <span class="o">=</span> <span class="n">data_mean_region_happiness</span><span class="p">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Happiness"</span><span class="p">:</span> <span class="s">"Happiness_std"</span><span class="p">})</span>
<span class="n">data_mean_std_merged</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">data_std_region_happiness</span><span class="p">,</span> <span class="n">data_mean_region_happiness</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span> <span class="s">"inner"</span><span class="p">,</span> <span class="n">on</span> <span class="o">=</span> <span class="s">"Region"</span><span class="p">)</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">fig</span><span class="p">.</span><span class="n">set_size_inches</span><span class="p">(</span><span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">)</span>
<span class="n">rp1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">regplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data_mean_std_merged</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s">"Happiness_mean"</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">"Happiness_std"</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">ax</span><span class="p">)</span>
<span class="n">rp1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Regression of happiness scores' standard deviation onto mean scores"</span><span class="p">)</span>
<span class="n">rp1</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span> <span class="o">=</span> <span class="s">"Mean happiness score"</span><span class="p">,</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s">"Standard deviation of happiness scores"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Text(0.5, 0, 'Mean happiness score'),
 Text(0, 0.5, 'Standard deviation of happiness scores')]
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_137_1.png" alt="png" /></p>

<p>Of course, we have very little data in this case, so the regression like is at best a rough indication of a general trend discussed earlier. This model assumes that the underlying relationship is linear, which is most likely not true in this case. Having said that, the slope of the regression line tends to lend at least some support to our hypothesis - that more well-developed countries, which have higher mean happiness scores, have lower variability of these scores.</p>

<p>So far, we have only focused on the overall happiness scores, but it’ll also be worth to look at how each factor contributes to that score on a per-region basis. Unfortunately, the sum of individual factor scores doesn’t sum to the happiness score. We can still calculate % contribution of each factor compared to the sum of factor values:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_melt_factors</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"Year"</span><span class="p">,</span> <span class="s">"Country"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s">"Region"</span><span class="p">])</span>
<span class="n">data_factor_agg_sum</span> <span class="o">=</span> <span class="n">data_happiness_melt_factors</span><span class="p">.</span><span class="n">groupby</span><span class="p">([</span><span class="s">"Region"</span><span class="p">,</span> <span class="s">"variable"</span><span class="p">]).</span><span class="n">agg</span><span class="p">({</span><span class="s">"value"</span><span class="p">:</span> <span class="s">"sum"</span><span class="p">})</span>
<span class="n">data_factor_percentage_agg_region</span> <span class="o">=</span> <span class="n">data_factor_agg_sum</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="n">level</span> <span class="o">=</span> <span class="mi">0</span><span class="p">).</span><span class="nb">apply</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">x</span> <span class="o">*</span> <span class="mi">100</span> <span class="o">/</span> <span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">.</span><span class="nb">sum</span><span class="p">())).</span><span class="n">reset_index</span><span class="p">()</span>

<span class="n">bp2</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">data_factor_percentage_agg_region</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s">"value"</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">"Region"</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">"variable"</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s">"bar"</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">bp2</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"% contribution of each factor towards happiness score"</span><span class="p">)</span>
<span class="n">bp2</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span> <span class="o">=</span> <span class="s">"% of sum of factors"</span><span class="p">,</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s">"Region"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Text(0.5, 6.8000000000000185, '% of sum of factors'),
 Text(34.02353993055556, 0.5, 'Region')]
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_140_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_factor_percentage_agg_region_min</span> <span class="o">=</span> <span class="n">data_factor_percentage_agg_region</span>
<span class="n">data_factor_percentage_agg_region_max</span> <span class="o">=</span> <span class="n">data_factor_percentage_agg_region</span><span class="p">[</span><span class="s">"variable"</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span>

<span class="k">def</span> <span class="nf">calculate_range_for_variable</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">variable_value</span><span class="p">,</span> <span class="n">variable_column_name</span> <span class="o">=</span> <span class="s">"variable"</span><span class="p">):</span>
    <span class="n">value_min</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">variable_column_name</span><span class="p">]</span> <span class="o">==</span> <span class="n">variable_value</span><span class="p">].</span><span class="nb">min</span><span class="p">()</span>
    <span class="n">value_max</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="n">variable_column_name</span><span class="p">]</span> <span class="o">==</span> <span class="n">variable_value</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span>
    
    <span class="k">return</span> <span class="n">value_max</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span> <span class="o">-</span> <span class="n">value_min</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>

<span class="n">variable_values_set</span> <span class="o">=</span> <span class="p">{</span><span class="s">"Family"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">}</span>

<span class="k">print</span><span class="p">(</span><span class="s">"Range of values for % contribution towards happiness score:"</span><span class="p">)</span>
<span class="k">for</span> <span class="n">variable_value</span> <span class="ow">in</span> <span class="n">variable_values_set</span><span class="p">:</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"{}: {} %-points"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">variable_value</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">calculate_range_for_variable</span><span class="p">(</span><span class="n">data_factor_percentage_agg_region</span><span class="p">,</span> <span class="n">variable_value</span><span class="p">),</span> <span class="mi">2</span><span class="p">)))</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n</span><span class="s">Standard deviation of % contribution values for each factor:"</span><span class="p">)</span>
<span class="n">data_factor_percentage_agg_region</span><span class="p">.</span><span class="n">groupby</span><span class="p">(</span><span class="s">"variable"</span><span class="p">).</span><span class="n">std</span><span class="p">().</span><span class="n">reset_index</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Range of values for % contribution towards happiness score:
Trust: 4.77 %-points
Generosity: 6.27 %-points
Health: 7.02 %-points
Freedom: 4.55 %-points
Family: 8.77 %-points
GDP: 10.19 %-points

Standard deviation of % contribution values for each factor:
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variable</th>
      <th>value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Family</td>
      <td>2.984138</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Freedom</td>
      <td>1.786329</td>
    </tr>
    <tr>
      <th>2</th>
      <td>GDP</td>
      <td>3.344855</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Generosity</td>
      <td>2.335433</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Health</td>
      <td>2.009339</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Trust</td>
      <td>1.369057</td>
    </tr>
  </tbody>
</table>
</div>

<p>We can see that the biggest range and standard deviation of % contribution values is in GDP, while the range and standard deviation of % contributions values are the smallest for Freedom. This hints at the possibility of GDP being the factor that, out of the ones considered here, is the least consistent in making people happy. In other words, in some coutries money makes people happy to a larger degree than in other countries. This sonds plausible - in developed countries, it’s more likely that a given individual will earn enough money to satisfy all basic needs that bring the most happiness. As discussed earlier, after a certain earnings threshold, money seems to have little to no influence on happiness.</p>

<p>This theory, however, seems to not be supported by the data. We can clearly see that the importance of GDP doesn’t increase as the level of a given region’s development deccreases. In other words - some poorer regions treat money as a less important factor contributing to their happiness than better-developed regions.</p>

<p>On the other hand, factors such as Freedom and Trust seems to have low variability in terms of % of contribution to each factor’s sum, suggesting that there is a higher degree of agreement across the world about how important they are in terms of influencing happiness.</p>

<h4 id="biggest-changes-in-happiness-scores">Biggest changes in happiness scores</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_score_melt</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">.</span><span class="n">drop</span><span class="p">([</span><span class="s">"Year"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s">"Country"</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">])</span>
<span class="n">data_happiness_score_melt</span> <span class="o">=</span> <span class="n">data_happiness_score_melt</span><span class="p">[</span><span class="n">data_happiness_score_melt</span><span class="p">[</span><span class="s">"variable"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"Happiness"</span><span class="p">]</span>
<span class="n">data_happiness_2015_melt</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">[</span><span class="n">data_happiness_concat</span><span class="p">[</span><span class="s">"Year"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2015</span><span class="p">].</span><span class="n">drop</span><span class="p">([</span><span class="s">"Year"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s">"Country"</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">])</span>
<span class="n">data_happiness_2019_melt</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">[</span><span class="n">data_happiness_concat</span><span class="p">[</span><span class="s">"Year"</span><span class="p">]</span> <span class="o">==</span> <span class="mi">2019</span><span class="p">].</span><span class="n">drop</span><span class="p">([</span><span class="s">"Year"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">).</span><span class="n">melt</span><span class="p">(</span><span class="n">id_vars</span><span class="o">=</span><span class="p">[</span><span class="s">"Country"</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">])</span>
<span class="n">data_happiness_2015_melt</span> <span class="o">=</span> <span class="n">data_happiness_2015_melt</span><span class="p">.</span><span class="n">set_index</span><span class="p">([</span><span class="s">"Country"</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">,</span> <span class="s">"variable"</span><span class="p">])</span>
<span class="n">data_happiness_2019_melt</span> <span class="o">=</span> <span class="n">data_happiness_2019_melt</span><span class="p">.</span><span class="n">set_index</span><span class="p">([</span><span class="s">"Country"</span><span class="p">,</span> <span class="s">"Region"</span><span class="p">,</span> <span class="s">"variable"</span><span class="p">])</span>
<span class="n">data_happiness_2019_minus_2015</span> <span class="o">=</span> <span class="n">data_happiness_2019_melt</span><span class="p">.</span><span class="n">subtract</span><span class="p">(</span><span class="n">data_happiness_2015_melt</span><span class="p">).</span><span class="n">reset_index</span><span class="p">().</span><span class="n">dropna</span><span class="p">()</span>

<span class="n">bp3</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data_happiness_2019_minus_2015</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="s">"value"</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="s">"Region"</span><span class="p">,</span> <span class="n">kind</span> <span class="o">=</span> <span class="s">"box"</span><span class="p">,</span> <span class="n">height</span> <span class="o">=</span> <span class="mi">8</span><span class="p">)</span>
<span class="n">bp3</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Distribution of happiness score changes for each region"</span><span class="p">)</span>
<span class="n">bp3</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span> <span class="o">=</span> <span class="s">"Happiness score"</span><span class="p">,</span> <span class="n">ylabel</span> <span class="o">=</span> <span class="s">"Region"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"black"</span><span class="p">,</span> <span class="n">linestyle</span> <span class="o">=</span> <span class="s">"-."</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;matplotlib.lines.Line2D at 0x7ff6af4c85b0&gt;
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_144_1.png" alt="png" /></p>

<p>Once again we can see some interesting things:</p>

<ol>
  <li>There were regions which, collectively, got more happy, as well as ones which got less happy</li>
  <li>Less well-developed regions tend to have a bigger variability in happiness score differences
    <ul>
      <li>However, there are exceptions such as the Middle East and Northern Africa</li>
    </ul>
  </li>
  <li>There seems to be some spatial autocorrelation - e.g. Western and Eastern Europe both have positive mean happiness score differences, while all Asian regions have negative mean differences</li>
</ol>

<h3 id="modelling-happiness-scores">Modelling happiness scores</h3>

<p>Based on the above analysis and discovered relationships, a natural question arises: can we model happiness scores as a function of the available variables?</p>

<p>To begin with, let’s start with a simple linear regression model. It has multiple benefits:</p>
<ol>
  <li>Allows us to do both predictive and inferential modelling</li>
  <li>Is easily interpretable</li>
  <li>Does not require large amounts of training data (which we don’t have)</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">from</span> <span class="nn">statsmodels.formula.api</span> <span class="kn">import</span> <span class="n">ols</span>
<span class="kn">from</span> <span class="nn">statsmodels.regression.linear_model</span> <span class="kn">import</span> <span class="n">OLS</span>
<span class="kn">from</span> <span class="nn">math</span> <span class="kn">import</span> <span class="n">floor</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>

<span class="k">def</span> <span class="nf">train_test_split_custom</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="mf">0.25</span><span class="p">):</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">size_test</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">n</span> <span class="o">*</span> <span class="n">test_size</span><span class="p">)</span>
    <span class="n">idx_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">choice</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]),</span> <span class="n">size</span><span class="o">=</span><span class="n">size_test</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
    <span class="n">idx_train</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">idx_test</span><span class="p">))</span>
    <span class="n">df_test</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx_test</span><span class="p">]</span>
    <span class="n">df_train</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">idx_train</span><span class="p">]</span>
    
    <span class="k">return</span> <span class="n">df_train</span><span class="p">,</span> <span class="n">df_test</span>

<span class="k">def</span> <span class="nf">k_fold_cv</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y_col_name</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">is_lasso</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">):</span>
    <span class="c1"># Shuffle data
</span>    <span class="n">df_shuffled</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">sample</span><span class="p">(</span><span class="n">frac</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">seed</span><span class="p">).</span><span class="n">reset_index</span><span class="p">()</span>
    <span class="n">n</span> <span class="o">=</span> <span class="n">df_shuffled</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">fold_size</span> <span class="o">=</span> <span class="n">floor</span><span class="p">(</span><span class="n">n</span> <span class="o">/</span> <span class="n">k</span><span class="p">)</span>
    
    <span class="n">predictor_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">columns</span><span class="p">)</span>
    <span class="n">predictor_names</span><span class="p">.</span><span class="n">remove</span><span class="p">(</span><span class="n">y_col_name</span><span class="p">)</span>
    
    <span class="n">y_true_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">y_pred_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">mse_list</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">params_list</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">if</span> <span class="n">is_lasso</span><span class="p">:</span>
        <span class="n">L1_wt</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">L1_wt</span> <span class="o">=</span> <span class="mi">0</span>
    
    <span class="k">for</span> <span class="n">fold_idx</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="o">+</span><span class="mi">1</span><span class="p">):</span>
        <span class="n">idx_start</span> <span class="o">=</span> <span class="p">(</span><span class="n">fold_idx</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">fold_size</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="n">idx_end</span> <span class="o">=</span> <span class="n">fold_idx</span> <span class="o">*</span> <span class="n">fold_size</span>
        <span class="n">train_range</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">idx_start</span><span class="p">,</span> <span class="n">idx_end</span><span class="o">+</span><span class="mi">1</span><span class="p">))</span>
        
        <span class="n">data_train</span> <span class="o">=</span> <span class="n">df_shuffled</span><span class="p">[</span><span class="n">df_shuffled</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">isin</span><span class="p">(</span><span class="n">train_range</span><span class="p">)]</span>
        <span class="n">data_test</span> <span class="o">=</span> <span class="n">df_shuffled</span><span class="p">[</span><span class="o">~</span><span class="n">df_shuffled</span><span class="p">.</span><span class="n">index</span><span class="p">.</span><span class="n">isin</span><span class="p">(</span><span class="n">train_range</span><span class="p">)]</span>
        
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">data_train</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">y_col_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">X_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">data_test</span><span class="p">.</span><span class="n">drop</span><span class="p">(</span><span class="n">y_col_name</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">))</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">data_train</span><span class="p">[</span><span class="n">y_col_name</span><span class="p">])</span>
        <span class="n">y_test</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">data_test</span><span class="p">[</span><span class="n">y_col_name</span><span class="p">])</span>
        
        <span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span>
        <span class="n">model_fitted</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">()</span>
        <span class="n">model_fitted_reg</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit_regularized</span><span class="p">(</span><span class="n">L1_wt</span><span class="o">=</span><span class="n">L1_wt</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="n">model_fitted</span><span class="p">.</span><span class="n">params</span><span class="p">)</span>
        
        <span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">predictor_names</span><span class="p">,</span> <span class="n">model_fitted_reg</span><span class="p">.</span><span class="n">params</span><span class="p">))</span>
        
        <span class="n">y_pred</span> <span class="o">=</span> <span class="n">model_fitted_reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">y_true_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_test</span><span class="p">)</span>
        <span class="n">y_pred_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">y_pred</span><span class="p">)</span>
        
        <span class="n">mse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_test</span> <span class="o">-</span> <span class="n">y_pred</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>
        <span class="n">mse_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">mse</span><span class="p">)</span>
        <span class="n">params_list</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">mse_list</span><span class="p">,</span> <span class="n">params_list</span>
</code></pre></div></div>

<h4 id="unregularized-multiple-regression">Unregularized multiple regression</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">TEST_SIZE</span> <span class="o">=</span> <span class="mf">0.25</span>

<span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">[[</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]]</span>
<span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span> <span class="o">=</span> <span class="n">train_test_split_custom</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">TEST_SIZE</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">ols</span><span class="p">(</span><span class="s">"Happiness ~ GDP + Family + Health + Freedom + Trust + Generosity"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_train</span><span class="p">).</span><span class="n">fit</span><span class="p">()</span>
<span class="n">reg</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>        <td>Happiness</td>    <th>  R-squared:         </th> <td>   0.778</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.776</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   339.6</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 29 May 2021</td> <th>  Prob (F-statistic):</th> <td>3.99e-186</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:22:59</td>     <th>  Log-Likelihood:    </th> <td> -462.88</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>   587</td>      <th>  AIC:               </th> <td>   939.8</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   580</td>      <th>  BIC:               </th> <td>   970.4</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>  <td>    2.1775</td> <td>    0.089</td> <td>   24.389</td> <td> 0.000</td> <td>    2.002</td> <td>    2.353</td>
</tr>
<tr>
  <th>GDP</th>        <td>    1.1727</td> <td>    0.092</td> <td>   12.771</td> <td> 0.000</td> <td>    0.992</td> <td>    1.353</td>
</tr>
<tr>
  <th>Family</th>     <td>    0.6311</td> <td>    0.090</td> <td>    6.984</td> <td> 0.000</td> <td>    0.454</td> <td>    0.809</td>
</tr>
<tr>
  <th>Health</th>     <td>    1.0316</td> <td>    0.148</td> <td>    6.974</td> <td> 0.000</td> <td>    0.741</td> <td>    1.322</td>
</tr>
<tr>
  <th>Freedom</th>    <td>    1.3187</td> <td>    0.187</td> <td>    7.068</td> <td> 0.000</td> <td>    0.952</td> <td>    1.685</td>
</tr>
<tr>
  <th>Trust</th>      <td>    0.7169</td> <td>    0.247</td> <td>    2.901</td> <td> 0.004</td> <td>    0.231</td> <td>    1.202</td>
</tr>
<tr>
  <th>Generosity</th> <td>    0.8496</td> <td>    0.200</td> <td>    4.256</td> <td> 0.000</td> <td>    0.458</td> <td>    1.242</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 8.625</td> <th>  Durbin-Watson:     </th> <td>   1.533</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.013</td> <th>  Jarque-Bera (JB):  </th> <td>   9.427</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.218</td> <th>  Prob(JB):          </th> <td> 0.00897</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.442</td> <th>  Cond. No.          </th> <td>    23.5</td>
</tr>
</table>
<p><br /><br />Notes:<br />[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</p>

<p>Our multiple linear regression model does fairly okay, being able to explain ~77% of variability in happiness scores. All coefficients seem to have very small p-values, suggesting that they are significantly different from 0 (which would imply no relationship between a given coefficient and the response variable).</p>

<p>Out of all the coefficients, it seems that GDP has a very high influence on happiness score, something we discovered in our explaoratory data analysis. Surprisingly, however, Freedom turns out to have <em>the</em> highest influence on happiness scores.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">rmse</span><span class="p">(</span><span class="n">y_hat</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">((</span><span class="n">y_hat</span> <span class="o">-</span> <span class="n">y</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rmse_reg</span> <span class="o">=</span> <span class="n">rmse</span><span class="p">(</span><span class="n">reg</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">),</span> <span class="n">data_train</span><span class="p">[</span><span class="s">"Happiness"</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">rmse_reg</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.5772
</code></pre></div></div>

<p>Let’s see if we can improve the model by transforming the predictor with the most non-linear relationship with Happiness - Trust. The relationship between these looks a bit like Hapiness = log(Trust):</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="p">(</span><span class="n">data_train</span><span class="p">[</span><span class="s">"Trust"</span><span class="p">]),</span> <span class="n">y</span><span class="o">=</span><span class="n">data_train</span><span class="p">[</span><span class="s">"Happiness"</span><span class="p">])</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>&lt;AxesSubplot:xlabel='Trust', ylabel='Happiness'&gt;
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_155_1.png" alt="png" /></p>

<p>Let’s try applying exp(Trust) to see if RMSE improves:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">reg_exp</span> <span class="o">=</span> <span class="n">ols</span><span class="p">(</span><span class="s">"Happiness ~ GDP + Family + Health + Freedom + np.exp(Trust) + Generosity"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_train</span><span class="p">).</span><span class="n">fit</span><span class="p">()</span>
<span class="n">reg_exp</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>        <td>Happiness</td>    <th>  R-squared:         </th> <td>   0.778</td> 
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.776</td> 
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   338.7</td> 
</tr>
<tr>
  <th>Date:</th>             <td>Sat, 29 May 2021</td> <th>  Prob (F-statistic):</th> <td>7.41e-186</td>
</tr>
<tr>
  <th>Time:</th>                 <td>11:35:24</td>     <th>  Log-Likelihood:    </th> <td> -463.50</td> 
</tr>
<tr>
  <th>No. Observations:</th>      <td>   587</td>      <th>  AIC:               </th> <td>   941.0</td> 
</tr>
<tr>
  <th>Df Residuals:</th>          <td>   580</td>      <th>  BIC:               </th> <td>   971.6</td> 
</tr>
<tr>
  <th>Df Model:</th>              <td>     6</td>      <th>                     </th>     <td> </td>    
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    
</tr>
</table>
<table class="simpletable">
<tr>
        <td></td>           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>     <td>    1.6520</td> <td>    0.211</td> <td>    7.812</td> <td> 0.000</td> <td>    1.237</td> <td>    2.067</td>
</tr>
<tr>
  <th>GDP</th>           <td>    1.1764</td> <td>    0.092</td> <td>   12.800</td> <td> 0.000</td> <td>    0.996</td> <td>    1.357</td>
</tr>
<tr>
  <th>Family</th>        <td>    0.6264</td> <td>    0.090</td> <td>    6.929</td> <td> 0.000</td> <td>    0.449</td> <td>    0.804</td>
</tr>
<tr>
  <th>Health</th>        <td>    1.0318</td> <td>    0.148</td> <td>    6.968</td> <td> 0.000</td> <td>    0.741</td> <td>    1.323</td>
</tr>
<tr>
  <th>Freedom</th>       <td>    1.3362</td> <td>    0.186</td> <td>    7.168</td> <td> 0.000</td> <td>    0.970</td> <td>    1.702</td>
</tr>
<tr>
  <th>np.exp(Trust)</th> <td>    0.5330</td> <td>    0.199</td> <td>    2.676</td> <td> 0.008</td> <td>    0.142</td> <td>    0.924</td>
</tr>
<tr>
  <th>Generosity</th>    <td>    0.8589</td> <td>    0.200</td> <td>    4.298</td> <td> 0.000</td> <td>    0.466</td> <td>    1.251</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 8.506</td> <th>  Durbin-Watson:     </th> <td>   1.534</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.014</td> <th>  Jarque-Bera (JB):  </th> <td>   9.270</td>
</tr>
<tr>
  <th>Skew:</th>          <td>-0.217</td> <th>  Prob(JB):          </th> <td> 0.00971</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.437</td> <th>  Cond. No.          </th> <td>    29.9</td>
</tr>
</table>
<p><br /><br />Notes:<br />[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">rmse_reg_exp</span> <span class="o">=</span> <span class="n">rmse</span><span class="p">(</span><span class="n">reg_exp</span><span class="p">.</span><span class="n">predict</span><span class="p">(</span><span class="n">data_test</span><span class="p">),</span> <span class="n">data_train</span><span class="p">[</span><span class="s">"Happiness"</span><span class="p">])</span>
<span class="k">print</span><span class="p">(</span><span class="nb">round</span><span class="p">(</span><span class="n">rmse_reg_exp</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>0.578
</code></pre></div></div>

<p>While the p-value for the Trust coefficient fell significantly compared to the non-transformed version, the RMSE is only a little bit lower. All in all, it seems that this is a slightly superior model.</p>

<p>What do our regression coefficients mean? Let’s take two examples: Health and np.exp(Trust):</p>

<ul>
  <li>
    <p>Health (1.0318) - this coefficient tells us that, holding all other predictors constant, increasing the value of this predictor by one unit leads to an increase in Happiness score by 1.0318 units.</p>
  </li>
  <li>
    <p>Family (0.6263) - for each 1-unit increase in Family score, there is a corresponding 0.62-unit increase in Hapiness score. It’s important to note that this relationship is still <em>positive</em>, despite the coefficient being &lt; 1. It simply means that the relationship is less pronounced. Only if the coefficient was &lt; 0, the relationship would be negative.</p>
  </li>
</ul>

<h4 id="regularized-regression">Regularized regression</h4>

<h5 id="ridge">Ridge</h5>

<p>Let’s now fit a multiple linear regression model with variable selection, namely: ridge regression. I went with ridge because I expect all variables to have at least <em>some</em> influence on the happiness score, which fits the ridge assumption that no coefficients are == 0:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">[[</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"Happiness"</span><span class="p">])</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">TEST_SIZE</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">IS_LASSO</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1">#Ridge with mild regularization (alpha = 0.1)
</span><span class="n">mse_list</span><span class="p">,</span> <span class="n">param_list</span> <span class="o">=</span> <span class="n">k_fold_cv</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">is_lasso</span><span class="o">=</span><span class="n">IS_LASSO</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">best_mse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">mse_list</span><span class="p">)</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="n">param_list</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse_list</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"best MSE: "</span><span class="p">,</span> <span class="n">best_mse</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"best params: "</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>best MSE:  0.7557017961348407
best params:  {'GDP': 0.0011351234485528796, 'Family': 1.4014860150221962, 'Health': 1.8112771726037473, 'Freedom': 1.2700676610264563, 'Trust': 1.1807256380699207, 'Generosity': 0.4368528326596003}
</code></pre></div></div>

<p>We can see that the MSE we got using 10-fold cross-validation is ~ 0.75. Let’s try picking an optimal amount of regularization by cross-validating the alpha parameter across a range of values:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="c1"># We will average parameter values from each run of cross-validation, e.g. if there are 10 folds, we will average parameter values from these folds
</span><span class="k">def</span> <span class="nf">average_dict_key_values</span><span class="p">(</span><span class="n">dict_in_list</span><span class="p">):</span>
    <span class="n">dict_out</span> <span class="o">=</span> <span class="p">{}</span>
    
    <span class="c1"># Initialize dict with key names and set their values to 0
</span>    <span class="n">dict_out</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">dict_in_list</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="n">keys</span><span class="p">()}</span>
    
    <span class="k">for</span> <span class="n">dict_in</span> <span class="ow">in</span> <span class="n">dict_in_list</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">dict_in</span><span class="p">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">dict_out</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">+=</span> <span class="n">value</span>
    
    <span class="k">return</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="o">/</span> <span class="nb">len</span><span class="p">(</span><span class="n">dict_in_list</span><span class="p">)</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">dict_out</span><span class="p">.</span><span class="n">items</span><span class="p">()}</span>


<span class="k">def</span> <span class="nf">cv_alpha</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">y_col_name</span><span class="p">,</span> <span class="n">alpha_list</span><span class="p">,</span> <span class="n">is_lasso</span><span class="p">):</span>
    <span class="n">mse_list_mean</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">param_list_mean</span> <span class="o">=</span> <span class="p">[]</span>
    
    <span class="k">for</span> <span class="n">alpha_val</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">alpha_list</span><span class="p">):</span>
        <span class="n">mse_list</span><span class="p">,</span> <span class="n">param_list</span> <span class="o">=</span> <span class="n">k_fold_cv</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">df</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="n">y_col_name</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">is_lasso</span><span class="o">=</span><span class="n">is_lasso</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_val</span><span class="p">)</span>
        <span class="n">mse_list_mean</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">mean</span><span class="p">(</span><span class="n">mse_list</span><span class="p">))</span>
        <span class="n">param_list_mean</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">average_dict_key_values</span><span class="p">(</span><span class="n">param_list</span><span class="p">))</span>
        
    
    <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">alpha_list</span><span class="p">,</span> <span class="n">mse_list_mean</span><span class="p">)),</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">alpha_list</span><span class="p">,</span> <span class="n">param_list_mean</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">alpha_list</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">alpha_to_mse_cv_dict</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">cv_alpha</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="n">alpha_list</span><span class="o">=</span><span class="n">alpha_list</span><span class="p">,</span> <span class="n">is_lasso</span><span class="o">=</span><span class="n">IS_LASSO</span><span class="p">)</span>
<span class="n">alpha_lowest_mse</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">.</span><span class="n">get</span><span class="p">)</span>
<span class="n">mse_lowest</span> <span class="o">=</span> <span class="n">alpha_to_mse_cv_dict</span><span class="p">[</span><span class="n">alpha_lowest_mse</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 100/100 [00:04&lt;00:00, 21.91it/s]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lp1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">.</span><span class="n">keys</span><span class="p">()),</span> <span class="n">y</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">.</span><span class="n">values</span><span class="p">()))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">mse_lowest</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Validation MSE as a function of alpha"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"alpha"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Validation MSE"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Lowest MSE for alpha = {}: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">mse_lowest</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Lowest MSE for alpha = 0.01: 0.627
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_168_1.png" alt="png" /></p>

<p>We obtain the lowest validation MSE at alpha = 0.01, beyond which the MSE increases in a linear fashion. The lowest validation MSE is around 0.13 lower than the MSE for the unregularized model. Let’s get the coefficients for the model with alpha = 0.01:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span>
<span class="n">model_fitted</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">()</span>
<span class="c1"># Ridge
</span><span class="n">model_fitted_reg</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit_regularized</span><span class="p">(</span><span class="n">L1_wt</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">IS_LASSO</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="n">model_fitted</span><span class="p">.</span><span class="n">params</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">model_fitted_reg</span><span class="p">.</span><span class="n">params</span><span class="p">))</span>
<span class="n">df_coefs</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">params</span><span class="p">.</span><span class="n">items</span><span class="p">())</span>
<span class="n">df_coefs</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">"variable_name"</span><span class="p">,</span> <span class="s">"coefficient_value"</span><span class="p">]</span>
<span class="n">df_coefs</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variable_name</th>
      <th>coefficient_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GDP</td>
      <td>1.110135</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Family</td>
      <td>1.903571</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Health</td>
      <td>1.373473</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Freedom</td>
      <td>2.022813</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Trust</td>
      <td>0.761936</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Generosity</td>
      <td>1.718897</td>
    </tr>
  </tbody>
</table>
</div>

<p>If we compare the coefficients of our regularized ridge regression model to the coefficients of the unregularized one, we note several things:</p>
<ol>
  <li>Freedom is recognized by both models as the variable having the strongest effect on happiness score</li>
  <li>While GDP is the variable with the 2nd strongest influence on happiness by the unregularized model (measured by coefficient value), it is also regarded as the 2nd least “influential” variable by the regularized model.</li>
</ol>

<p>Perhaps we can get some insights into the relative “importance” (degree of influence) of each predictor by plotting coefficient values as a function of alpha? Let’s see:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_concat</span><span class="p">[[</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"Happiness"</span><span class="p">])</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">TEST_SIZE</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1"># Ridge with mild regularization (alpha = 0.1)
</span><span class="n">mse_list</span><span class="p">,</span> <span class="n">param_list</span> <span class="o">=</span> <span class="n">k_fold_cv</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">is_lasso</span><span class="o">=</span><span class="n">IS_LASSO</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">best_mse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">mse_list</span><span class="p">)</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="n">param_list</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse_list</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="n">average_dict_key_values</span><span class="p">(</span><span class="n">param_list</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{'GDP': 0.003991375470960662, 'Family': 1.2265927759529673, 'Health': 1.15826163046805, 'Freedom': 0.7731165688287568, 'Trust': 0.5759775398271861, 'Generosity': 0.21913083156803922}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># alpha_list = 10**np.linspace(-5, 1, 100)
# _, param_list_mean = cv_alpha(df=data, y_col_name="Happiness", alpha_list=alpha_list, is_lasso=IS_LASSO)
</span></code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">plot_alpha_vs_coefficients</span><span class="p">(</span><span class="n">is_lasso</span><span class="p">,</span> <span class="n">alpha_list</span><span class="p">,</span> <span class="n">y_col_name</span><span class="p">):</span>
    <span class="n">alpha_to_mse_cv_dict</span><span class="p">,</span> <span class="n">param_list_mean</span> <span class="o">=</span> <span class="n">cv_alpha</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="n">y_col_name</span><span class="p">,</span> <span class="n">alpha_list</span><span class="o">=</span><span class="n">alpha_list</span><span class="p">,</span> <span class="n">is_lasso</span><span class="o">=</span><span class="n">is_lasso</span><span class="p">)</span>
    <span class="n">df_alpha_to_mean_param_value</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s">"alpha"</span><span class="p">,</span> <span class="s">"variable_name"</span><span class="p">,</span> <span class="s">"value"</span><span class="p">])</span>

    <span class="c1"># Create a dataframe in wide format for plotting with seaborn
</span>    <span class="n">row_idx</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">alpha</span><span class="p">,</span> <span class="n">dict_mean_params</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">param_list_mean</span><span class="p">.</span><span class="n">items</span><span class="p">()):</span>
        <span class="n">variable_names</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dict_mean_params</span><span class="p">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">variable_values</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">dict_mean_params</span><span class="p">.</span><span class="n">values</span><span class="p">())</span>
        <span class="k">for</span> <span class="p">(</span><span class="n">variable_name</span><span class="p">,</span> <span class="n">variable_value</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">variable_names</span><span class="p">,</span> <span class="n">variable_values</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">variable_name</span> <span class="o">==</span> <span class="n">y_col_name</span><span class="p">:</span>
                <span class="k">continue</span>
            <span class="n">df_alpha_to_mean_param_value</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">row_idx</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">alpha</span><span class="p">,</span> <span class="n">variable_name</span><span class="p">,</span> <span class="n">variable_value</span><span class="p">]</span>
            <span class="n">row_idx</span> <span class="o">+=</span> <span class="mi">1</span>
    
    <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">6</span><span class="p">))</span>
    <span class="n">lp2</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"alpha"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"value"</span><span class="p">,</span> <span class="n">hue</span><span class="o">=</span><span class="s">"variable_name"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df_alpha_to_mean_param_value</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
    <span class="n">lp2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Coefficient values as a function of log(alpha)"</span><span class="p">)</span>
    <span class="c1"># Green line indicates best alpha value
</span>    <span class="n">alpha_lowest_mse</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">.</span><span class="n">get</span><span class="p">)</span>
    <span class="n">plt</span><span class="p">.</span><span class="n">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="n">color</span> <span class="o">=</span> <span class="s">"green"</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="s">"--"</span><span class="p">)</span>
    <span class="n">lp2</span><span class="p">.</span><span class="n">set_xscale</span><span class="p">(</span><span class="s">"log"</span><span class="p">)</span>
    <span class="n">lp2</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">"log(alpha)"</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span> <span class="s">"coefficient value"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">alpha_list</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plot_alpha_vs_coefficients</span><span class="p">(</span><span class="n">is_lasso</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">alpha_list</span><span class="o">=</span><span class="n">alpha_list</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Happiness"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 100/100 [00:04&lt;00:00, 22.40it/s]
100%|██████████| 100/100 [00:02&lt;00:00, 34.06it/s]
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_176_1.png" alt="png" /></p>

<p>This chart looks pretty interesting! Note that some coefficient values decrease monotonically (e.g. Trust), while some increase and only then decrease (e.g. Health). This gives us a proxy for the degree of “importance” of each variable, as decided by the model. If we assess variable importance this way, we can conclude that Health and Family seem to be the most important in terms of affecting happiness scores, as their coefficient values are relatively large, and they initially increase.</p>

<h5 id="lasso">Lasso</h5>

<p>Let’s see what happens to the coefficients if we use lasso regression:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">alpha_list</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plot_alpha_vs_coefficients</span><span class="p">(</span><span class="n">is_lasso</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">alpha_list</span><span class="o">=</span><span class="n">alpha_list</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Happiness"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 100/100 [01:19&lt;00:00,  1.25it/s]
100%|██████████| 100/100 [00:02&lt;00:00, 36.39it/s]
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_180_1.png" alt="png" /></p>

<p>With lasso regression we can see that, eventually, all coefficients get shrunk to 0, as expected. In this case, we could treat the coefficients that got shrunken to 0 earlier as “less important”, and ones that got shrunken later as “more important”. In other words, we would assign a rank to each coefficient indicating when it’s = 0, which would indicate the importance, with small values (e.g. rank 1) indicating small importance.</p>

<p>Using the above interpretation, we can rank the coefficients as follows (ordered by decreasing importance):</p>

<ol>
  <li>Health</li>
  <li>Family</li>
  <li>Trust</li>
  <li>Freedom</li>
  <li>Generosity</li>
  <li>GDP</li>
</ol>

<p>Clearly, our cross-validated lasso model indicates that Health is the most “important” variable in influencing happiness score, while GDP is the least important one.</p>

<h3 id="summary-1">Summary</h3>

<p>In the analysis of the 2015 - 2019 happiness data, we looked at both uivariate and bivariate distributions of variables influencing happiness scores. Some of the takeaways include:</p>

<ol>
  <li>While money does seem to contribute to overall happiness, the degree to which it does so is very inconcistent spatially</li>
  <li>Money tends to be a rather poor predictor of happiness.</li>
  <li>Factors that affect hapinness to a large degree, fairly consistently, include good health (Health), good relationships (Family), or instritutional trust (Trust)</li>
  <li>Different factors such as Health or Family tend to change their importance over time. Their importance also varies spatially</li>
  <li>Some regions (e.g. Europe) seem to be more happy, on average, than other regions (e.g. Asia)</li>
</ol>

<h2 id="2015-happiness--suicide-data">2015 Happiness + suicide data</h2>

<h3 id="a-first-look-at-the-data-1">A first look at the data</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_suicide</span><span class="p">.</span><span class="n">head</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Country</th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Region</th>
      <th>Year</th>
      <th>Suicides_no</th>
      <th>Population</th>
      <th>Suicides_per_100k</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Switzerland</td>
      <td>7.587</td>
      <td>1.39651</td>
      <td>1.34951</td>
      <td>0.94143</td>
      <td>0.66557</td>
      <td>0.41978</td>
      <td>0.29678</td>
      <td>Western Europe</td>
      <td>2015</td>
      <td>1073.0</td>
      <td>7892502.0</td>
      <td>13.721667</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Iceland</td>
      <td>7.561</td>
      <td>1.30232</td>
      <td>1.40223</td>
      <td>0.94784</td>
      <td>0.62877</td>
      <td>0.14145</td>
      <td>0.43630</td>
      <td>Western Europe</td>
      <td>2015</td>
      <td>40.0</td>
      <td>308554.0</td>
      <td>11.720833</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Denmark</td>
      <td>7.527</td>
      <td>1.32548</td>
      <td>1.36058</td>
      <td>0.87464</td>
      <td>0.64938</td>
      <td>0.48357</td>
      <td>0.34139</td>
      <td>Western Europe</td>
      <td>2015</td>
      <td>564.0</td>
      <td>5383060.0</td>
      <td>10.118333</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Norway</td>
      <td>7.522</td>
      <td>1.45900</td>
      <td>1.33095</td>
      <td>0.88521</td>
      <td>0.66973</td>
      <td>0.36503</td>
      <td>0.34699</td>
      <td>Western Europe</td>
      <td>2015</td>
      <td>590.0</td>
      <td>4882909.0</td>
      <td>11.369167</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Finland</td>
      <td>7.406</td>
      <td>1.29025</td>
      <td>1.31826</td>
      <td>0.88911</td>
      <td>0.64169</td>
      <td>0.41372</td>
      <td>0.23351</td>
      <td>Western Europe</td>
      <td>2015</td>
      <td>731.0</td>
      <td>5181797.0</td>
      <td>13.432500</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_suicide</span><span class="p">.</span><span class="n">describe</span><span class="p">()</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Happiness</th>
      <th>GDP</th>
      <th>Family</th>
      <th>Health</th>
      <th>Freedom</th>
      <th>Trust</th>
      <th>Generosity</th>
      <th>Year</th>
      <th>Suicides_no</th>
      <th>Population</th>
      <th>Suicides_per_100k</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>53.000000</td>
      <td>53.000000</td>
      <td>53.000000</td>
      <td>53.000000</td>
      <td>53.000000</td>
      <td>53.000000</td>
      <td>53.000000</td>
      <td>53.0</td>
      <td>53.000000</td>
      <td>5.300000e+01</td>
      <td>53.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>6.218264</td>
      <td>1.132585</td>
      <td>1.157052</td>
      <td>0.807952</td>
      <td>0.480777</td>
      <td>0.172053</td>
      <td>0.240484</td>
      <td>2015.0</td>
      <td>3074.037736</td>
      <td>2.969755e+07</td>
      <td>11.144072</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.921575</td>
      <td>0.237022</td>
      <td>0.184932</td>
      <td>0.127157</td>
      <td>0.148750</td>
      <td>0.148547</td>
      <td>0.134501</td>
      <td>0.0</td>
      <td>6897.861698</td>
      <td>5.252175e+07</td>
      <td>6.515303</td>
    </tr>
    <tr>
      <th>min</th>
      <td>4.297000</td>
      <td>0.474280</td>
      <td>0.385620</td>
      <td>0.276880</td>
      <td>0.076990</td>
      <td>0.006490</td>
      <td>0.000000</td>
      <td>2015.0</td>
      <td>34.000000</td>
      <td>3.085540e+05</td>
      <td>1.083333</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>5.548000</td>
      <td>1.007610</td>
      <td>1.078600</td>
      <td>0.731720</td>
      <td>0.406720</td>
      <td>0.042320</td>
      <td>0.128000</td>
      <td>2015.0</td>
      <td>342.000000</td>
      <td>3.583382e+06</td>
      <td>6.454167</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>6.329000</td>
      <td>1.147230</td>
      <td>1.219630</td>
      <td>0.811600</td>
      <td>0.516490</td>
      <td>0.135860</td>
      <td>0.232400</td>
      <td>2015.0</td>
      <td>1062.000000</td>
      <td>9.114524e+06</td>
      <td>10.577500</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>6.946000</td>
      <td>1.302320</td>
      <td>1.280170</td>
      <td>0.892840</td>
      <td>0.603650</td>
      <td>0.245580</td>
      <td>0.330880</td>
      <td>2015.0</td>
      <td>2872.000000</td>
      <td>3.969962e+07</td>
      <td>14.617500</td>
    </tr>
    <tr>
      <th>max</th>
      <td>7.587000</td>
      <td>1.690420</td>
      <td>1.402230</td>
      <td>1.025250</td>
      <td>0.669730</td>
      <td>0.522080</td>
      <td>0.576300</td>
      <td>2015.0</td>
      <td>44189.000000</td>
      <td>3.000785e+08</td>
      <td>32.123333</td>
    </tr>
  </tbody>
</table>
</div>

<p>The most striking observation of the above data summary is the range in suicide rates. The minimum value (1.08) is ~30x lower than the maximum value (32.12)!</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pp2</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">pairplot</span><span class="p">(</span><span class="n">data_happiness_suicide</span><span class="p">)</span>
<span class="n">pp2</span><span class="p">.</span><span class="n">fig</span><span class="p">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s">"Pairplot of happiness + suicide data for year 2015"</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="mf">1.02</span><span class="p">,</span> <span class="n">fontsize</span> <span class="o">=</span> <span class="mi">20</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.02, 'Pairplot of happiness + suicide data for year 2015')
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_189_1.png" alt="png" /></p>

<p>From the pairplot, we can see that there might be some relationships present between the suicide rates and some variables contributing to happiness scores.</p>

<h3 id="univariate-distributions-1">Univariate distributions</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hp1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"Suicides_no"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_happiness_suicide</span><span class="p">)</span>
<span class="n">hp1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Distribution of number of suicides"</span><span class="p">)</span>
<span class="n">hp1</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">"Number of suicides"</span><span class="p">,</span> <span class="n">ylabel</span><span class="o">=</span><span class="s">"Count"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Text(0.5, 0, 'Number of suicides'), Text(0, 0.5, 'Count')]
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_192_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cdfp1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">ecdfplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"Suicides_no"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_happiness_suicide</span><span class="p">)</span>
<span class="n">cdfp1</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"CDF of number of suicides"</span><span class="p">)</span>
<span class="n">cdfp1</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">"Number of suicides"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Text(0.5, 0, 'Number of suicides')]
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_193_1.png" alt="png" /></p>

<p>The distribution of the number of suicides is very right (positively) skewed. Over 90% of countries saw &lt; 10000 suicides in 2015.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">hp2</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">histplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_happiness_suicide</span><span class="p">)</span>
<span class="n">hp2</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Distribution of suicide rate (/100k)"</span><span class="p">)</span>
<span class="n">hp2</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">"Suicides / 100k"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Text(0.5, 0, 'Suicides / 100k')]
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_195_1.png" alt="png" /></p>

<p>Here, we can see a much lessright-skewed distribution.</p>

<h3 id="bivariate-distributions-1">Bivariate distributions</h3>

<p>Let’s now investigate joint distributions of suicide rates and “happiness variables”:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">create_pairwise_corrplot</span><span class="p">(</span><span class="n">data_happiness_suicide</span><span class="p">,</span> <span class="mi">2015</span><span class="p">,</span> <span class="n">fig</span><span class="p">,</span> <span class="n">ax</span><span class="p">,</span> <span class="s">"suicide"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_199_0.png" alt="png" /></p>

<p>Compared to correlations between happiness variables, the correlations for suicide-related variables are much weaker. The strongest correlations are between suicide rate and Family, Trust, and Generosity.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_scatterplot_kde</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">scatter</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">scatterplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">kde</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">kdeplot</span><span class="p">(</span><span class="n">data</span> <span class="o">=</span> <span class="n">df</span><span class="p">,</span> <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">scatter</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"{} vs {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_scatterplot_kde</span><span class="p">(</span><span class="n">data_happiness_suicide</span><span class="p">,</span> <span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_202_0.png" alt="png" /></p>

<p>The distribution is fairly “round”, indicating a weak, if any, relationship between suicide rate and happiness scores.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_scatterplot_kde</span><span class="p">(</span><span class="n">data_happiness_suicide</span><span class="p">,</span> <span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_204_0.png" alt="png" /></p>

<p>The above plot shows that as suicide rates increase, so do Family scores. We also spot an outlier. The relationship is fairly weak.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_scatterplot_kde</span><span class="p">(</span><span class="n">data_happiness_suicide</span><span class="p">,</span> <span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_206_0.png" alt="png" /></p>

<p>Here, the relationship between suicide rate and Trust scores is negative - as suicide rates increase, trust decreases.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">create_scatterplot_kde</span><span class="p">(</span><span class="n">data_happiness_suicide</span><span class="p">,</span> <span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_208_0.png" alt="png" /></p>

<p>Once again, the relationship between suicide rate and Generosity scores is negative. It seems a bit stronger than the previous ones, but is still weak-to-moderate.</p>

<p>All in all, there doesn’t seem to be much correlation between suicide rates and Happiness scores, or any happiness-related variables.</p>

<h3 id="spatiality-of-suicide-rates">Spatiality of suicide rates</h3>

<p>Let’s further investigate if there are some regions that have significantly higher or lower suicide rates.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bp4</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data_happiness_suicide</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"Region"</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">"box"</span><span class="p">,</span> <span class="n">height</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">bp4</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Suicide rate distribution by region"</span><span class="p">)</span>
<span class="n">bp4</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="nb">set</span><span class="p">(</span><span class="n">xlabel</span><span class="o">=</span><span class="s">"Suicides / 100k"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[Text(0.5, 6.800000000000004, 'Suicides / 100k')]
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_213_1.png" alt="png" /></p>

<p>Interestingly, there is a very wide variation in the distributions of suicide rates:</p>

<ol>
  <li>Mean suicide rates vary from as low as ~ 0 in Sub-Saharan Africa to ~17.5 in Central and Eastern Europe
    <ul>
      <li>This could be caused by genuinely lower suicide rates in Sub-Saharan Africa, or by underreporting of suicides. Without access to data collection methods, it’s impossible to conclude anything.</li>
    </ul>
  </li>
  <li>There seems to be some spatial autocorrelation at play once again. Regions closer to each other, such as Western Europe and Central and Eastern Europe tend to have more similar distributions than more distant regions. Another example is Southeastern Asia and Eastern Asia, which have almost equal means.</li>
  <li>There is a very clear outlier in Latin America and Caribbean</li>
</ol>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_suicide</span><span class="p">[</span><span class="n">data_happiness_suicide</span><span class="p">[</span><span class="s">"Region"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"Latin America and Caribbean"</span><span class="p">].</span><span class="nb">max</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Country                                  Uruguay
Happiness                                  7.187
GDP                                      1.10715
Family                                   1.24823
Health                                   0.85857
Freedom                                  0.60362
Trust                                    0.24558
Generosity                               0.33363
Region               Latin America and Caribbean
Year                                        2015
Suicides_no                              11163.0
Population                           191087085.0
Suicides_per_100k                      22.501667
dtype: object
</code></pre></div></div>

<p>Uruguay is the country with unusually high suicide rates in its region.</p>

<h4 id="central-and-eastern-europe">Central and Eastern Europe</h4>

<p>Let’s look a bit closer at Central and Eastern Europe’s wide variability in suicide rates.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">pd</span><span class="p">.</span><span class="n">options</span><span class="p">.</span><span class="n">mode</span><span class="p">.</span><span class="n">chained_assignment</span> <span class="o">=</span> <span class="bp">None</span>
<span class="n">data_happiness_suicide_europe_eastern_central</span> <span class="o">=</span> <span class="n">data_happiness_suicide</span><span class="p">[</span><span class="n">data_happiness_suicide</span><span class="p">[</span><span class="s">"Region"</span><span class="p">]</span> <span class="o">==</span> <span class="s">"Central and Eastern Europe"</span><span class="p">]</span>
<span class="n">data_happiness_suicide_europe_eastern_central</span><span class="p">[</span><span class="s">"suicide_rate_above_mean"</span><span class="p">]</span> <span class="o">=</span> <span class="n">data_happiness_suicide_europe_eastern_central</span><span class="p">[</span><span class="s">"Suicides_per_100k"</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">data_happiness_suicide_europe_eastern_central</span><span class="p">[</span><span class="s">"Suicides_per_100k"</span><span class="p">].</span><span class="n">mean</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">bp5</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">catplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">data_happiness_suicide_europe_eastern_central</span><span class="p">,</span> <span class="n">x</span><span class="o">=</span><span class="s">"Region"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="n">hue</span> <span class="o">=</span> <span class="s">"suicide_rate_above_mean"</span><span class="p">,</span> <span class="n">kind</span><span class="o">=</span><span class="s">"box"</span><span class="p">)</span>
<span class="n">bp5</span><span class="p">.</span><span class="n">ax</span><span class="p">.</span><span class="n">set_title</span><span class="p">(</span><span class="s">"Happiness"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Text(0.5, 1.0, 'Happiness')
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_220_1.png" alt="png" /></p>

<p>Happiness scores tend to have a much wider range of values, as well as a slightly <em>lower</em> mean for countries where suicide rates are below mean rate. This is a somewhat counterintuitive result, as we would expect Happiness scores to be higher, on average, for countries with lower suicide rates. The difference in mean values is fairly small, however.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_suicide_europe_eastern_central</span><span class="p">.</span><span class="nb">min</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Country                                       Armenia
Happiness                                       4.297
GDP                                           0.47428
Family                                        0.38562
Health                                        0.53886
Freedom                                       0.19847
Trust                                         0.00649
Generosity                                    0.02641
Region                     Central and Eastern Europe
Year                                             2015
Suicides_no                                      74.0
Population                                  1243450.0
Suicides_per_100k                            2.373333
suicide_rate_above_mean                         False
dtype: object
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_happiness_suicide_europe_eastern_central</span><span class="p">.</span><span class="nb">max</span><span class="p">()</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Country                                       Ukraine
Happiness                                       6.505
GDP                                           1.18498
Family                                        1.27948
Health                                        0.87337
Freedom                                       0.60855
Trust                                         0.38331
Generosity                                     0.3003
Region                     Central and Eastern Europe
Year                                             2015
Suicides_no                                    7574.0
Population                                 40345446.0
Suicides_per_100k                           32.123333
suicide_rate_above_mean                          True
dtype: object
</code></pre></div></div>

<p>The above countries are from two ends of the suicide rate distribution. Armenia has a staggeringly 13x lower suicide rate than Ukraine, while also having lower mean Happiness score! Without more detailed data about each countries, as well as more in-depth knowledge about the socioeconomic factors, we can only speculate as to the reasons behind this: be it underreporting of suicides, religious factors, or varying degrees of cultural acceptance of suicide.</p>

<h3 id="modelling-suicide-rates">Modelling suicide rates</h3>

<h4 id="unregularized-multiple-regression-1">Unregularized multiple regression</h4>

<p>We will now investigate what the models tell us above the relative importance of happiness-related variables in predicting suicide rates.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">SEED</span> <span class="o">=</span> <span class="mi">42</span>
<span class="n">TEST_SIZE</span> <span class="o">=</span> <span class="mf">0.25</span>

<span class="n">feature_names_suicide</span> <span class="o">=</span> <span class="p">[</span><span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_suicide</span><span class="p">[[</span><span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]]</span>
<span class="n">data_train</span><span class="p">,</span> <span class="n">data_test</span> <span class="o">=</span> <span class="n">train_test_split_custom</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">TEST_SIZE</span><span class="p">)</span>
<span class="n">reg</span> <span class="o">=</span> <span class="n">ols</span><span class="p">(</span><span class="s">"Suicides_per_100k ~ Happiness + GDP + Family + Health + Freedom + Trust + Generosity"</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data_train</span><span class="p">).</span><span class="n">fit</span><span class="p">()</span>
<span class="n">reg</span><span class="p">.</span><span class="n">summary</span><span class="p">()</span>
</code></pre></div></div>

<table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>    <td>Suicides_per_100k</td> <th>  R-squared:         </th> <td>   0.230</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>        <th>  Adj. R-squared:    </th> <td>   0.061</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>   <th>  F-statistic:       </th> <td>   1.362</td>
</tr>
<tr>
  <th>Date:</th>             <td>Wed, 12 May 2021</td>  <th>  Prob (F-statistic):</th>  <td> 0.255</td> 
</tr>
<tr>
  <th>Time:</th>                 <td>19:03:23</td>      <th>  Log-Likelihood:    </th> <td> -124.36</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    40</td>       <th>  AIC:               </th> <td>   264.7</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    32</td>       <th>  BIC:               </th> <td>   278.2</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     7</td>       <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>     <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
       <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P&gt;|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th>  <td>  -12.1257</td> <td>   10.218</td> <td>   -1.187</td> <td> 0.244</td> <td>  -32.940</td> <td>    8.688</td>
</tr>
<tr>
  <th>Happiness</th>  <td>    1.4291</td> <td>    2.592</td> <td>    0.551</td> <td> 0.585</td> <td>   -3.851</td> <td>    6.709</td>
</tr>
<tr>
  <th>GDP</th>        <td>    6.6115</td> <td>    6.826</td> <td>    0.969</td> <td> 0.340</td> <td>   -7.293</td> <td>   20.516</td>
</tr>
<tr>
  <th>Family</th>     <td>    5.0715</td> <td>    9.817</td> <td>    0.517</td> <td> 0.609</td> <td>  -14.925</td> <td>   25.068</td>
</tr>
<tr>
  <th>Health</th>     <td>    5.1331</td> <td>   10.728</td> <td>    0.478</td> <td> 0.636</td> <td>  -16.718</td> <td>   26.984</td>
</tr>
<tr>
  <th>Freedom</th>    <td>    6.0501</td> <td>   13.423</td> <td>    0.451</td> <td> 0.655</td> <td>  -21.291</td> <td>   33.391</td>
</tr>
<tr>
  <th>Trust</th>      <td>  -11.2175</td> <td>   10.548</td> <td>   -1.064</td> <td> 0.296</td> <td>  -32.702</td> <td>   10.267</td>
</tr>
<tr>
  <th>Generosity</th> <td>  -18.7641</td> <td>    9.608</td> <td>   -1.953</td> <td> 0.060</td> <td>  -38.336</td> <td>    0.808</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 9.217</td> <th>  Durbin-Watson:     </th> <td>   2.040</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.010</td> <th>  Jarque-Bera (JB):  </th> <td>   8.286</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.923</td> <th>  Prob(JB):          </th> <td>  0.0159</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 4.249</td> <th>  Cond. No.          </th> <td>    110.</td>
</tr>
</table>
<p><br /><br />Notes:<br />[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</p>

<p>The model indicates that all coefficients’ values are not significantly different from 0 - we fail to reject the null hypothesis that they are == 0. This means that, according to the model, no variables have significant correlation with suicide rates.</p>

<h4 id="regularized-regression-1">Regularized regression</h4>

<p>We will now fit regularized lasso and ridge models to see how quickly different coefficient values are shrunk. Before doing so, we need to see what values of parameter alpha yeild best results in terms of validation MSE.</p>

<h5 id="ridge-1">Ridge</h5>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">IS_LASSO</span> <span class="o">=</span> <span class="bp">False</span>

<span class="n">alpha_list</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">alpha_to_mse_cv_dict</span><span class="p">,</span> <span class="n">param_list_mean</span> <span class="o">=</span> <span class="n">cv_alpha</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="n">alpha_list</span><span class="o">=</span><span class="n">alpha_list</span><span class="p">,</span> <span class="n">is_lasso</span><span class="o">=</span><span class="n">IS_LASSO</span><span class="p">)</span>
<span class="n">alpha_lowest_mse</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">.</span><span class="n">get</span><span class="p">)</span>
<span class="n">mse_lowest</span> <span class="o">=</span> <span class="n">alpha_to_mse_cv_dict</span><span class="p">[</span><span class="n">alpha_lowest_mse</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 1000/1000 [00:43&lt;00:00, 23.08it/s]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lp1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">.</span><span class="n">keys</span><span class="p">()),</span> <span class="n">y</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">.</span><span class="n">values</span><span class="p">()))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">mse_lowest</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Validation MSE as a function of alpha"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"alpha"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Validation MSE"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Lowest MSE for alpha = {}: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">mse_lowest</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Lowest MSE for alpha = 0.9749649183484176: 85.162
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_234_1.png" alt="png" /></p>

<p>We obtain the lowest validation MSE at alpha ~= 0.975, beyond which the MSE increases monotonically. Let’s get the coefficients for the best model:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_suicide</span><span class="p">[[</span><span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s">"Health"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"Suicides_per_100k"</span><span class="p">])</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">TEST_SIZE</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">IS_LASSO</span> <span class="o">=</span> <span class="bp">False</span>

<span class="c1">#Ridge with mild regularization (alpha = 0.1)
</span><span class="n">mse_list</span><span class="p">,</span> <span class="n">param_list</span> <span class="o">=</span> <span class="n">k_fold_cv</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">is_lasso</span><span class="o">=</span><span class="n">IS_LASSO</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">best_mse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">mse_list</span><span class="p">)</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="n">param_list</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse_list</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"best MSE: "</span><span class="p">,</span> <span class="n">best_mse</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"best params: "</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>best MSE:  41.97509283903308
best params:  {'Happiness': 0.0830634174071037, 'GDP': 1.2235817388557328, 'Family': 0.355195591299412, 'Health': 0.06636282546814885, 'Freedom': 0.6765408309873714, 'Trust': -0.0016135710331761782, 'Generosity': -0.25379195150758005}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span>
<span class="n">model_fitted</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">()</span>
<span class="c1"># Ridge
</span><span class="n">model_fitted_reg</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit_regularized</span><span class="p">(</span><span class="n">L1_wt</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">IS_LASSO</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="n">model_fitted</span><span class="p">.</span><span class="n">params</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">model_fitted_reg</span><span class="p">.</span><span class="n">params</span><span class="p">))</span>
<span class="n">df_coefs</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">params</span><span class="p">.</span><span class="n">items</span><span class="p">())</span>
<span class="n">df_coefs</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">"variable_name"</span><span class="p">,</span> <span class="s">"coefficient_value"</span><span class="p">]</span>
<span class="n">df_coefs</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variable_name</th>
      <th>coefficient_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GDP</td>
      <td>1.843706</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Family</td>
      <td>2.534032</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Health</td>
      <td>2.821371</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Freedom</td>
      <td>1.843706</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Trust</td>
      <td>0.786679</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Generosity</td>
      <td>0.018360</td>
    </tr>
  </tbody>
</table>
</div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">alpha_list</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
<span class="n">plot_alpha_vs_coefficients</span><span class="p">(</span><span class="n">is_lasso</span><span class="o">=</span><span class="n">IS_LASSO</span><span class="p">,</span> <span class="n">alpha_list</span><span class="o">=</span><span class="n">alpha_list</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Suicides_per_100k"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 100/100 [00:04&lt;00:00, 21.77it/s]
100%|██████████| 100/100 [00:02&lt;00:00, 33.49it/s]
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_238_1.png" alt="png" /></p>

<p>While there seems to be some variation in when different coefficient values are shrunk to ~0, there isn’t as much variation as when we predicted happiness scores. This suggests that there is no variable that’s much more useful in predicting suicide rates than any other ones; most of them get shrunk to ~0 at log(alpha) ~= 10<sup>4</sup>.</p>

<h4 id="lasso-1">Lasso</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">IS_LASSO</span> <span class="o">=</span> <span class="bp">True</span>

<span class="n">alpha_list</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">100</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">alpha_to_mse_cv_dict</span><span class="p">,</span> <span class="n">param_list_mean</span> <span class="o">=</span> <span class="n">cv_alpha</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="n">alpha_list</span><span class="o">=</span><span class="n">alpha_list</span><span class="p">,</span> <span class="n">is_lasso</span><span class="o">=</span><span class="n">IS_LASSO</span><span class="p">)</span>
<span class="n">alpha_lowest_mse</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">.</span><span class="n">get</span><span class="p">)</span>
<span class="n">mse_lowest</span> <span class="o">=</span> <span class="n">alpha_to_mse_cv_dict</span><span class="p">[</span><span class="n">alpha_lowest_mse</span><span class="p">]</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 200/200 [00:36&lt;00:00,  5.46it/s]
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">lp1</span> <span class="o">=</span> <span class="n">sns</span><span class="p">.</span><span class="n">lineplot</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">.</span><span class="n">keys</span><span class="p">()),</span> <span class="n">y</span><span class="o">=</span><span class="nb">list</span><span class="p">(</span><span class="n">alpha_to_mse_cv_dict</span><span class="p">.</span><span class="n">values</span><span class="p">()))</span>
<span class="n">plt</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="n">mse_lowest</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">"red"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">title</span><span class="p">(</span><span class="s">"Validation MSE as a function of alpha"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s">"alpha"</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s">"Validation MSE"</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"Lowest MSE for alpha = {}: {}"</span><span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="nb">round</span><span class="p">(</span><span class="n">mse_lowest</span><span class="p">,</span> <span class="mi">3</span><span class="p">)))</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Lowest MSE for alpha = 2.8994228538829168: 75.282
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_242_1.png" alt="png" /></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="n">data_happiness_suicide</span><span class="p">[[</span><span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="s">"Happiness"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]]</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">data</span><span class="p">.</span><span class="n">reset_index</span><span class="p">(</span><span class="n">drop</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">matrix</span><span class="p">(</span><span class="n">data</span><span class="p">[[</span><span class="s">"Health"</span><span class="p">,</span> <span class="s">"GDP"</span><span class="p">,</span> <span class="s">"Family"</span><span class="p">,</span> <span class="s">"Health"</span><span class="p">,</span> <span class="s">"Freedom"</span><span class="p">,</span> <span class="s">"Trust"</span><span class="p">,</span> <span class="s">"Generosity"</span><span class="p">]])</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">array</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="s">"Suicides_per_100k"</span><span class="p">])</span>

<span class="n">X_train</span><span class="p">,</span> <span class="n">X_test</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">test_size</span><span class="o">=</span><span class="n">TEST_SIZE</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="c1">#Ridge with mild regularization (alpha = 0.1)
</span><span class="n">mse_list</span><span class="p">,</span> <span class="n">param_list</span> <span class="o">=</span> <span class="n">k_fold_cv</span><span class="p">(</span><span class="n">df</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Suicides_per_100k"</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">is_lasso</span><span class="o">=</span><span class="n">IS_LASSO</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="n">SEED</span><span class="p">)</span>

<span class="n">best_mse</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">mse_list</span><span class="p">)</span>
<span class="n">best_params</span> <span class="o">=</span> <span class="n">param_list</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="n">argmin</span><span class="p">(</span><span class="n">mse_list</span><span class="p">)]</span>
<span class="k">print</span><span class="p">(</span><span class="s">"best MSE: "</span><span class="p">,</span> <span class="n">best_mse</span><span class="p">)</span>
<span class="k">print</span><span class="p">(</span><span class="s">"best params: "</span><span class="p">,</span> <span class="n">best_params</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>best MSE:  44.495073292253664
best params:  {'Happiness': 0.02296993923673515, 'GDP': 1.6120930215198086, 'Family': 0.0, 'Health': 0.0, 'Freedom': 0.0, 'Trust': 0.0, 'Generosity': 0.0}
</code></pre></div></div>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">OLS</span><span class="p">(</span><span class="n">y_train</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span>
<span class="n">model_fitted</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">()</span>
<span class="c1"># Ridge
</span><span class="n">model_fitted_reg</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit_regularized</span><span class="p">(</span><span class="n">L1_wt</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span> <span class="k">if</span> <span class="n">IS_LASSO</span> <span class="k">else</span> <span class="mi">0</span><span class="p">),</span> <span class="n">alpha</span><span class="o">=</span><span class="n">alpha_lowest_mse</span><span class="p">,</span> <span class="n">start_params</span><span class="o">=</span><span class="n">model_fitted</span><span class="p">.</span><span class="n">params</span><span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">feature_names</span><span class="p">,</span> <span class="n">model_fitted_reg</span><span class="p">.</span><span class="n">params</span><span class="p">))</span>
<span class="n">df_coefs</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">.</span><span class="n">from_dict</span><span class="p">(</span><span class="n">params</span><span class="p">.</span><span class="n">items</span><span class="p">())</span>
<span class="n">df_coefs</span><span class="p">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s">"variable_name"</span><span class="p">,</span> <span class="s">"coefficient_value"</span><span class="p">]</span>
<span class="n">df_coefs</span>
</code></pre></div></div>

<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>variable_name</th>
      <th>coefficient_value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>GDP</td>
      <td>0.00000</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Family</td>
      <td>0.00000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Health</td>
      <td>8.12084</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Freedom</td>
      <td>0.00000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Trust</td>
      <td>0.00000</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Generosity</td>
      <td>0.00000</td>
    </tr>
  </tbody>
</table>
</div>

<p>At the best alpha value, we can see that all but one coefficients got shrunk to 0. The only remaining non-zero coefficient turns out to be for Health.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">alpha_list</span> <span class="o">=</span> <span class="mi">10</span><span class="o">**</span><span class="n">np</span><span class="p">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">200</span><span class="p">)</span>
<span class="n">plot_alpha_vs_coefficients</span><span class="p">(</span><span class="n">is_lasso</span><span class="o">=</span><span class="n">IS_LASSO</span><span class="p">,</span> <span class="n">alpha_list</span><span class="o">=</span><span class="n">alpha_list</span><span class="p">,</span> <span class="n">y_col_name</span><span class="o">=</span><span class="s">"Suicides_per_100k"</span><span class="p">)</span>
</code></pre></div></div>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>100%|██████████| 200/200 [02:33&lt;00:00,  1.30it/s]
100%|██████████| 200/200 [00:08&lt;00:00, 24.26it/s]
</code></pre></div></div>

<p><img src="/images/happiness_files/happiness_246_1.png" alt="png" /></p>

<p>For lasso regression, there is more variability as to when coefficient values are shrunk to 0. Visually, it’s hard to determine the order of coefficient values shrinking. What’s more, some coefficient values switch between positive and negative values, indicating a fair amount of model’s “indecisiveness” as to their values.</p>

<h3 id="summary-2">Summary</h3>
<p>The analysis of happiness + suicide data for year 2015 allowed us to have a peek into whether there exist any relaitonships between happiness and suicide rates, as well as into the spatiality of suicide rates. The key conclusions are as follows:</p>

<ol>
  <li>There exist both positive and negative correlations between happiness-related variables and suicide rates, pointing to a lack of consistent relationship between happiness and suicide rates</li>
  <li>All bivariate distributions of happiness-related variables and suicide rates have a fairly roud shape, indicating no clear relationships between them</li>
  <li>Mean suicide rates vary widely across the world, both within continents and within regions</li>
  <li>There is some degree of spatial autocorrelation between suicide rates in neighbouring countries / regions</li>
</ol>

<h2 id="conclusions">Conclusions</h2>

<p>The above analysis of two datasets consisted of exploratory data analysis and inferential modelling. The most important conclusions we can draw are:</p>

<p><strong>1. Money is not as important as we think in making us happy</strong></p>

<p><strong>2. Good relationships and good health are important contributors to our happiness</strong></p>

<p><strong>3. The degree to which you’re happy / likely to commit a suicide varies with where you live in the world</strong></p>

<p><strong>4. High / low suicide rates don’t imply low / high happiness scores</strong></p>

</div>


<div class="related">
  <h2>Related posts</h2>
  <ul class="related-posts">
    
      <li>
        <h3>
          <a href="/2021/05/29/introduction/">
            Another attempt at a personal blog
            <small>29 May 2021</small>
          </a>
        </h3>
      </li>
    
  </ul>
</div>


      </div>
    </div>

    <label for="sidebar-checkbox" class="sidebar-toggle"></label>

    <script src='/public/js/script.js'></script>
  </body>
</html>
